{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8165591,
          "sourceType": "datasetVersion",
          "datasetId": 4831777
        }
      ],
      "dockerImageVersionId": 30513,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Fake/Real News torch RoBERTa+PEFT",
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "# import kagglehub\n",
        "# clmentbisaillon_fake_and_real_news_dataset_path = kagglehub.dataset_download('clmentbisaillon/fake-and-real-news-dataset')\n",
        "\n",
        "# print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "sqeDOo2GR5E5"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 104
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fake/Real News torch RoBERTa+PEFT"
      ],
      "metadata": {
        "id": "J88oJLwWR5E8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/code/stpeteishii/twitch-reviews-torch-roberta"
      ],
      "metadata": {
        "id": "Vd9JI_q5R5FA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## About PEFT\n",
        "PEFT (Parameter-Efficient Fine-Tuning) is a technique used in machine learning, particularly in the context of fine-tuning large pre-trained models like transformers (e.g., BERT, GPT, etc.) for specific tasks. The primary goal of PEFT is to reduce the number of parameters that need to be updated during the fine-tuning process, which significantly decreases the computational cost and memory usage while maintaining or even improving performance.\n",
        "\n",
        "## Key Concepts of PEFT:\n",
        "Efficiency: By focusing only on a subset of parameters, PEFT avoids the need to fine-tune all parameters of the model, making the process faster and less resource-intensive.\n",
        "\n",
        "Memory and Computational Savings: PEFT drastically reduces the amount of GPU memory required, making it feasible to fine-tune very large models on smaller hardware setups.\n",
        "\n",
        "Performance Maintenance: Despite fine-tuning fewer parameters, PEFT techniques are often able to achieve comparable or even superior performance to full fine-tuning.\n",
        "\n",
        "Application Areas: PEFT is widely used in natural language processing (NLP), computer vision, and other AI tasks that involve large-scale models, allowing for efficient adaptation of general-purpose models to specific applications.\n",
        "\n",
        "## Techniques Used in PEFT:\n",
        "Adapters: Small neural network modules inserted into the layers of a pre-trained model that learn task-specific information without altering the main model weights.\n",
        "\n",
        "Low-Rank Adaptation (LoRA): A method that fine-tunes low-rank updates to the model weights, reducing the number of parameters that need to be trained.\n",
        "\n",
        "Prefix Tuning: Adds task-specific vectors (prefixes) to the input sequence that influence the model output, thus adapting the model without changing its core parameters.\n",
        "\n",
        "BitFit (Bias-Only Fine-Tuning): Fine-tunes only the bias terms of the model, leaving the majority of the weights untouched.\n",
        "\n"
      ],
      "metadata": {
        "id": "uWrzdrS9R5FB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T02:08:40.618527Z",
          "iopub.execute_input": "2024-09-06T02:08:40.618964Z",
          "iopub.status.idle": "2024-09-06T02:08:59.578553Z",
          "shell.execute_reply.started": "2024-09-06T02:08:40.618916Z",
          "shell.execute_reply": "2024-09-06T02:08:59.577053Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRoM6TycR5FC",
        "outputId": "f0386c99-c0af-471e-9d4d-83e521a58a3f"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.6.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.31.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (1.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chardet"
      ],
      "metadata": {
        "papermill": {
          "duration": 13.253789,
          "end_time": "2023-06-28T07:17:40.715086",
          "exception": false,
          "start_time": "2023-06-28T07:17:27.461297",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-09-06T02:08:59.581265Z",
          "iopub.execute_input": "2024-09-06T02:08:59.581773Z",
          "iopub.status.idle": "2024-09-06T02:09:13.753536Z",
          "shell.execute_reply.started": "2024-09-06T02:08:59.581726Z",
          "shell.execute_reply": "2024-09-06T02:09:13.75203Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntYxgDaUR5FD",
        "outputId": "d8ddad8e-f1b0-4f51-fb1d-9364f6c207ab"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (5.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "debug = False\n",
        "debug2 = False"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.020191,
          "end_time": "2023-06-28T07:17:40.747178",
          "exception": false,
          "start_time": "2023-06-28T07:17:40.726987",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-09-06T02:09:13.755255Z",
          "iopub.execute_input": "2024-09-06T02:09:13.755653Z",
          "iopub.status.idle": "2024-09-06T02:09:13.762454Z",
          "shell.execute_reply.started": "2024-09-06T02:09:13.755615Z",
          "shell.execute_reply": "2024-09-06T02:09:13.761104Z"
        },
        "trusted": true,
        "id": "SF_CzNofR5FD"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, ConfusionMatrixDisplay\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import transformers\n",
        "import random\n",
        "import chardet\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "papermill": {
          "duration": 6.118647,
          "end_time": "2023-06-28T07:17:46.877542",
          "exception": false,
          "start_time": "2023-06-28T07:17:40.758895",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-09-06T02:09:13.765363Z",
          "iopub.execute_input": "2024-09-06T02:09:13.765796Z",
          "iopub.status.idle": "2024-09-06T02:09:19.883419Z",
          "shell.execute_reply.started": "2024-09-06T02:09:13.765762Z",
          "shell.execute_reply": "2024-09-06T02:09:19.882211Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKdeplLwR5FE",
        "outputId": "58202555-ee9c-4240-ecb6-4349a21f9d97"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_seed(SEED):\n",
        "\n",
        "    random.seed(SEED)\n",
        "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "SEED = 508\n",
        "random_seed(SEED)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.026662,
          "end_time": "2023-06-28T07:17:46.916292",
          "exception": false,
          "start_time": "2023-06-28T07:17:46.88963",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-09-06T02:09:19.884683Z",
          "iopub.execute_input": "2024-09-06T02:09:19.885332Z",
          "iopub.status.idle": "2024-09-06T02:09:19.899306Z",
          "shell.execute_reply.started": "2024-09-06T02:09:19.8853Z",
          "shell.execute_reply": "2024-09-06T02:09:19.898129Z"
        },
        "trusted": true,
        "id": "mQhL0AiJR5FE"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake=pd.read_csv('sampled_fake.csv')\n",
        "fake['label']='fake'\n",
        "true=pd.read_csv('sampled_true.csv')\n",
        "true['label']='true'\n",
        "data=pd.concat([fake[['label','text']],true[['label','text']]],axis=0).reset_index(drop=True)\n",
        "n=len(data)\n",
        "N=list(range(n))\n",
        "random.shuffle(N)\n",
        "data=data.iloc[N]\n",
        "display(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "COofZztrR5FE",
        "outputId": "4fc64783-66d2-444f-bef7-e867ab6042b7"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     label                                               text\n",
              "6158  true  NEW YORK (Reuters) - The race to succeed Repub...\n",
              "6843  true  SEOUL (Reuters) - North Korea used Chinese-mad...\n",
              "3224  fake  A group of people beat a man in a Brooklyn res...\n",
              "4212  true  ROME (Reuters) - Italy s anti-establishment 5-...\n",
              "390   fake   Communism begins where atheism begins. -Karl ...\n",
              "...    ...                                                ...\n",
              "4053  true  WELLINGTON (Reuters) - A final tally in New Ze...\n",
              "3437  fake  As usual Milwaukee s outspoken Sheriff David C...\n",
              "5436  true  WASHINGTON (Reuters) - When President Donald T...\n",
              "6441  true  JAKARTA (Reuters) - Indonesia s speaker of par...\n",
              "4438  true  HARARE (Reuters) - Zimbabwe s President Emmers...\n",
              "\n",
              "[8000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04e3e30e-3961-44bb-b0d0-5d0d6b7a901e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6158</th>\n",
              "      <td>true</td>\n",
              "      <td>NEW YORK (Reuters) - The race to succeed Repub...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6843</th>\n",
              "      <td>true</td>\n",
              "      <td>SEOUL (Reuters) - North Korea used Chinese-mad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3224</th>\n",
              "      <td>fake</td>\n",
              "      <td>A group of people beat a man in a Brooklyn res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4212</th>\n",
              "      <td>true</td>\n",
              "      <td>ROME (Reuters) - Italy s anti-establishment 5-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>fake</td>\n",
              "      <td>Communism begins where atheism begins. -Karl ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4053</th>\n",
              "      <td>true</td>\n",
              "      <td>WELLINGTON (Reuters) - A final tally in New Ze...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3437</th>\n",
              "      <td>fake</td>\n",
              "      <td>As usual Milwaukee s outspoken Sheriff David C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5436</th>\n",
              "      <td>true</td>\n",
              "      <td>WASHINGTON (Reuters) - When President Donald T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6441</th>\n",
              "      <td>true</td>\n",
              "      <td>JAKARTA (Reuters) - Indonesia s speaker of par...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4438</th>\n",
              "      <td>true</td>\n",
              "      <td>HARARE (Reuters) - Zimbabwe s President Emmers...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04e3e30e-3961-44bb-b0d0-5d0d6b7a901e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04e3e30e-3961-44bb-b0d0-5d0d6b7a901e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04e3e30e-3961-44bb-b0d0-5d0d6b7a901e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0d976913-d036-4965-9b74-58699ae94897\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d976913-d036-4965-9b74-58699ae94897')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0d976913-d036-4965-9b74-58699ae94897 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_e5ff9cc2-6a42-4562-bb4c-0b685f66d221\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e5ff9cc2-6a42-4562-bb4c-0b685f66d221 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8000,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"fake\",\n          \"true\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7717,\n        \"samples\": [\n          \" A Minneapolis man is being charged with criminal sexual conduct after being accused of raping a woman on a bus passing through Crookston Friday, according to the Crookston Times. Mohamed Harir Ayanle, 22, was released from the Northwest Regional Correction Center Monday on a $5,000 bond and on the condition that he does not leave Minnesota,  the Times reported.According to the criminal complaint filed with the Minnesota 9th Judicial District Court in Polk County, the suspect  just moved to Minnesota on September 22, 2016 from Somalia. Breitbart News contacted the Crookston Police Department and asked whether Ayanle spoke English, whether he arrived under the federal refugee resettlement program or a different immigration program, and for details on his current visa status, but did not receive a response.Breitbart News also contacted Catholic Charities of St. Paul and Lutheran Social Services, two of the largest resettlement agencies based in Minnesota, and asked if either had helped to resettle Ayanle, but did not receive a response. A sexual assault evidence kit was collected at RiverView Health and the Polk County Sheriff s Office is assisting in the continued investigation,  the Times added.Crookston, a city of 7,800 with a 15 person police force, is located 25 miles southeast of Grand Forks, North Dakota.  Breitbart News\",\n          \" (This March 22 story was corrected to remove reference to Inhofe being chairman in paragraph four) WASHINGTON (Reuters) - A U.S. Senate committee easily passed a bill on Wednesday to enable the nuclear regulator to license advanced nuclear reactors that backers say are safer than conventional plants and can help deal with a growing waste problem. The Nuclear Energy Innovation and Modernization Act requires the Nuclear Regulatory Commission to develop a regulatory framework to enable the licensing of advanced nuclear reactors that could come into development in 10 or 15 years.   The bill passed 18-3 in the Environment and Public Works Committee.  Republican Senator James Inhofe, said the bill is \\u201ccritical for the revitalization and improvement of our nation\\u2019s nuclear energy industry.\\u201d  The bill has brought together some Republicans eager to prevent the United States from falling behind China and Russia in nuclear innovation and Democrats who want to foster technologies that do not emit gases blamed for climate change. But the legislation faces a cloudy future.  The nuclear industry faces competition from cheap natural gas prices and the growing wind and solar power industries. It was uncertain whether the full Senate would debate the bill or if the measure would be absorbed into broader energy legislation. Democratic Senator Sheldon Whitehouse said the bill would help the United States keep its lead in innovation while finding possible solutions to the waste now kept in pools and in casks at conventional nuclear plant sites.    \\u201cIf we can get there, we will have done this country and the world a vital public service,\\u201d Whitehouse said of the potential for the advanced reactors to reduce the waste problem.  A fellow Democrat, Senator Kamala Harris of California - one of several lawmakers who want to see the country find comprehensive, permanent solutions to existing nuclear waste from conventional nuclear plants before moving ahead with new reactors - voted against the bill.  \\u201cSafely disposing of any radioactive material is a key priority of mine to ensure that we leave our environment pristine and unharmed for future generations,\\u201d Harris said, adding that she is willing to help improve the legislation. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns=['label','text']\n",
        "class_names=sorted(data['label'].unique().tolist())\n",
        "print(class_names)\n",
        "N=list(range(len(class_names)))\n",
        "normal_mapping=dict(zip(class_names,N))\n",
        "reverse_mapping=dict(zip(N,class_names))\n",
        "data['label']=data['label'].map(normal_mapping)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.240253,
          "end_time": "2023-06-28T07:18:29.143156",
          "exception": false,
          "start_time": "2023-06-28T07:18:28.902903",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:00.600551Z",
          "iopub.execute_input": "2024-04-21T15:27:00.600848Z",
          "iopub.status.idle": "2024-04-21T15:27:00.617294Z",
          "shell.execute_reply.started": "2024-04-21T15:27:00.600822Z",
          "shell.execute_reply": "2024-04-21T15:27:00.616443Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8xYSIfjR5FF",
        "outputId": "164c3b4e-5150-4afe-d8ac-86fee1ada124"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fake', 'true']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(data[0:3000], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.026581,
          "end_time": "2023-06-28T07:18:29.183917",
          "exception": false,
          "start_time": "2023-06-28T07:18:29.157336",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:00.618357Z",
          "iopub.execute_input": "2024-04-21T15:27:00.618653Z",
          "iopub.status.idle": "2024-04-21T15:27:00.668866Z",
          "shell.execute_reply.started": "2024-04-21T15:27:00.618628Z",
          "shell.execute_reply": "2024-04-21T15:27:00.667944Z"
        },
        "trusted": true,
        "id": "qD0zpdnIR5FG"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-uncased\")\n",
        "tokenizer = transformers.RobertaTokenizer.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "papermill": {
          "duration": 2.112898,
          "end_time": "2023-06-28T07:18:31.309109",
          "exception": false,
          "start_time": "2023-06-28T07:18:29.196211",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:00.67012Z",
          "iopub.execute_input": "2024-04-21T15:27:00.670721Z",
          "iopub.status.idle": "2024-04-21T15:27:04.921664Z",
          "shell.execute_reply.started": "2024-04-21T15:27:00.670688Z",
          "shell.execute_reply": "2024-04-21T15:27:04.92069Z"
        },
        "trusted": true,
        "id": "NpDFpkrAR5FH"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_s = train['text'].iloc[0]\n",
        "\n",
        "result1 = tokenizer.encode_plus(test_s)\n",
        "\n",
        "tokenizer.decode(result1[\"input_ids\"])"
      ],
      "metadata": {
        "papermill": {
          "duration": 5.697647,
          "end_time": "2023-06-28T07:18:37.019837",
          "exception": false,
          "start_time": "2023-06-28T07:18:31.32219",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:04.923052Z",
          "iopub.execute_input": "2024-04-21T15:27:04.923347Z",
          "iopub.status.idle": "2024-04-21T15:27:11.313477Z",
          "shell.execute_reply.started": "2024-04-21T15:27:04.923321Z",
          "shell.execute_reply": "2024-04-21T15:27:11.312494Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "yVK3jQIFR5FI",
        "outputId": "a950978a-9346-4592-c6d0-d5891c470de3"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>The gay mafia has a new corporate  Don. This is the only article you will need to read about the sheer stupidity of left-wing agitators who are crowing about the new religious freedom law in Indiana.Yesterday, Apple CEO Tim Cook, himself a gay man, published an op-ed in The Washington Post with this ominous title:  Pro-discrimination laws are dangerous.  Cook argues that religious freedom laws, like the one signed by Gov. Mike Pence of Indiana last week are  dangerous  to gay people.A debatable point. However, what is not debatable is this: laws that make homosexuality punishable by death are dangerous to gay people.That s why you might be surprised to learn that Cook s company, Apple, does business in four (4) countries that make homosexuality a capital crime. Those countries are Saudi Arabia, the United Arab Emirates, Nigeria, and Qatar.If you zip on over to this page, you can see the list of all of the countries where Apple does business. Those four countries are on the list.We anxiously await CNN s Andrew Cuomo or ABC s George Stephanopoulos to ask Tim Cook to appear on air and explain this glaring inconsistency, which should be obvious even to the average MSNBC viewer.However, we all know that won t happen.Via: DownTrend</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_s.split(\" \"))"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.022816,
          "end_time": "2023-06-28T07:18:37.055794",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.032978",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:11.314643Z",
          "iopub.execute_input": "2024-04-21T15:27:11.31493Z",
          "iopub.status.idle": "2024-04-21T15:27:11.32222Z",
          "shell.execute_reply.started": "2024-04-21T15:27:11.314899Z",
          "shell.execute_reply": "2024-04-21T15:27:11.321279Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNVMCc1PR5FJ",
        "outputId": "81b926d0-0f58-42a7-fd19-26cd0521cfca"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "215"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result2 = tokenizer.encode_plus(\n",
        "    test_s,\n",
        "    add_special_tokens = True,\n",
        "    max_length = 32,\n",
        "    pad_to_max_length = True,\n",
        "    truncation = True\n",
        ")"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.020965,
          "end_time": "2023-06-28T07:18:37.089429",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.068464",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:11.326177Z",
          "iopub.execute_input": "2024-04-21T15:27:11.326432Z",
          "iopub.status.idle": "2024-04-21T15:27:11.336362Z",
          "shell.execute_reply.started": "2024-04-21T15:27:11.326409Z",
          "shell.execute_reply": "2024-04-21T15:27:11.335725Z"
        },
        "trusted": true,
        "id": "nmas_4g4R5FJ"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(result2[\"input_ids\"])"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.02102,
          "end_time": "2023-06-28T07:18:37.123143",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.102123",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:11.337843Z",
          "iopub.execute_input": "2024-04-21T15:27:11.338107Z",
          "iopub.status.idle": "2024-04-21T15:27:11.349792Z",
          "shell.execute_reply.started": "2024-04-21T15:27:11.338081Z",
          "shell.execute_reply": "2024-04-21T15:27:11.348942Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6UCBu52vR5FK",
        "outputId": "4ca5105e-51f4-4a8e-e451-8da51264770b"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>The gay mafia has a new corporate  Don. This is the only article you will need to read about the sheer stupidity of left-wing agit</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sens = 32\n",
        "\n",
        "train = train.sort_values(\"label\").reset_index(drop=True)\n",
        "\n",
        "train[\"kfold\"] = train.index % 5\n",
        "\n",
        "p_train = train[train[\"kfold\"]!=0].reset_index(drop=True)\n",
        "p_valid = train[train[\"kfold\"]==0].reset_index(drop=True)\n",
        "\n",
        "p_test=test.reset_index(drop=True)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.030376,
          "end_time": "2023-06-28T07:18:37.166117",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.135741",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:11.350926Z",
          "iopub.execute_input": "2024-04-21T15:27:11.351248Z",
          "iopub.status.idle": "2024-04-21T15:27:11.361283Z",
          "shell.execute_reply.started": "2024-04-21T15:27:11.351214Z",
          "shell.execute_reply": "2024-04-21T15:27:11.360591Z"
        },
        "trusted": true,
        "id": "2rchzmmSR5FK"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'token_type_ids' no need in RoBERTa/DeBERTa"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.01246,
          "end_time": "2023-06-28T07:18:37.191756",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.179296",
          "status": "completed"
        },
        "tags": [],
        "id": "ZQ5R5xifR5FL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataSet(Dataset):\n",
        "\n",
        "    def __init__(self,sentences,targets):\n",
        "        self.sentences = sentences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        bert_sens = tokenizer.encode_plus(\n",
        "                                sentence,\n",
        "                                add_special_tokens = True,\n",
        "                                max_length = max_sens,\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True)\n",
        "\n",
        "        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n",
        "        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n",
        "\n",
        "        target = torch.tensor(self.targets[idx],dtype=torch.float)\n",
        "\n",
        "        return {\n",
        "                'ids': ids,\n",
        "                'mask': mask,\n",
        "\n",
        "                'targets': target\n",
        "            }"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.023548,
          "end_time": "2023-06-28T07:18:37.228036",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.204488",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:11.362223Z",
          "iopub.execute_input": "2024-04-21T15:27:11.362469Z",
          "iopub.status.idle": "2024-04-21T15:27:11.371986Z",
          "shell.execute_reply.started": "2024-04-21T15:27:11.362448Z",
          "shell.execute_reply": "2024-04-21T15:27:11.37122Z"
        },
        "trusted": true,
        "id": "edhj8g64R5FL"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = BERTDataSet(p_train[\"text\"],p_train[\"label\"])\n",
        "valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid[\"label\"])\n",
        "test_dataset = BERTDataSet(p_test[\"text\"],p_test[\"label\"])\n",
        "\n",
        "train_batch = 16\n",
        "valid_batch = 32\n",
        "test_batch = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=8,pin_memory=True)\n",
        "valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=8,pin_memory=True)\n",
        "test_dataloader = DataLoader(test_dataset,batch_size=test_batch,shuffle = False,num_workers=8,pin_memory=True)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.023996,
          "end_time": "2023-06-28T07:18:37.264616",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.24062",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:11.373088Z",
          "iopub.execute_input": "2024-04-21T15:27:11.373525Z",
          "iopub.status.idle": "2024-04-21T15:27:11.382953Z",
          "shell.execute_reply.started": "2024-04-21T15:27:11.373494Z",
          "shell.execute_reply": "2024-04-21T15:27:11.382072Z"
        },
        "trusted": true,
        "id": "unHchgSuR5FM"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\",num_labels=1)\n",
        "#model = transformers.BertForSequenceClassification.from_pretrained(\"../input/bert-base-uncased\",num_labels=1)"
      ],
      "metadata": {
        "papermill": {
          "duration": 5.239221,
          "end_time": "2023-06-28T07:18:42.516586",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.277365",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:11.384056Z",
          "iopub.execute_input": "2024-04-21T15:27:11.384979Z",
          "iopub.status.idle": "2024-04-21T15:27:22.908743Z",
          "shell.execute_reply.started": "2024-04-21T15:27:11.384943Z",
          "shell.execute_reply": "2024-04-21T15:27:22.907975Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKT2GMWLR5FM",
        "outputId": "ea2ef6d5-7d9c-424b-ba19-92598450fdbf"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# peft setting for roberta"
      ],
      "metadata": {
        "id": "lDN7-9tIR5FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#peft setting for roberta\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    inference_mode=False,\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1\n",
        ")\n",
        "\n",
        "lora_model = get_peft_model(model, lora_config)\n",
        "model = lora_model\n",
        "display(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Iv-vdFOdR5FN",
        "outputId": "e96c1c1b-62f2-4457-da05-a776d4db8e9d"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "PeftModelForSequenceClassification(\n",
              "  (base_model): LoraModel(\n",
              "    (model): RobertaForSequenceClassification(\n",
              "      (roberta): RobertaModel(\n",
              "        (embeddings): RobertaEmbeddings(\n",
              "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "          (token_type_embeddings): Embedding(1, 768)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder): RobertaEncoder(\n",
              "          (layer): ModuleList(\n",
              "            (0-11): 12 x RobertaLayer(\n",
              "              (attention): RobertaAttention(\n",
              "                (self): RobertaSdpaSelfAttention(\n",
              "                  (query): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): RobertaSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): RobertaIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): RobertaOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (classifier): ModulesToSaveWrapper(\n",
              "        (original_module): RobertaClassificationHead(\n",
              "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
              "        )\n",
              "        (modules_to_save): ModuleDict(\n",
              "          (default): RobertaClassificationHead(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "model.train()"
      ],
      "metadata": {
        "papermill": {
          "duration": 5.090094,
          "end_time": "2023-06-28T07:18:47.620511",
          "exception": false,
          "start_time": "2023-06-28T07:18:42.530417",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:22.909926Z",
          "iopub.execute_input": "2024-04-21T15:27:22.910275Z",
          "iopub.status.idle": "2024-04-21T15:27:23.209704Z",
          "shell.execute_reply.started": "2024-04-21T15:27:22.910245Z",
          "shell.execute_reply": "2024-04-21T15:27:23.208753Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qJ0CqRzR5FO",
        "outputId": "5465e1e1-d46e-4b58-db0b-e3ae633ed903"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSequenceClassification(\n",
              "  (base_model): LoraModel(\n",
              "    (model): RobertaForSequenceClassification(\n",
              "      (roberta): RobertaModel(\n",
              "        (embeddings): RobertaEmbeddings(\n",
              "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "          (token_type_embeddings): Embedding(1, 768)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder): RobertaEncoder(\n",
              "          (layer): ModuleList(\n",
              "            (0-11): 12 x RobertaLayer(\n",
              "              (attention): RobertaAttention(\n",
              "                (self): RobertaSdpaSelfAttention(\n",
              "                  (query): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (output): RobertaSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (intermediate): RobertaIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): RobertaOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (classifier): ModulesToSaveWrapper(\n",
              "        (original_module): RobertaClassificationHead(\n",
              "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
              "        )\n",
              "        (modules_to_save): ModuleDict(\n",
              "          (default): RobertaClassificationHead(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a in train_dataloader:\n",
        "    ids = a[\"ids\"].to(device)\n",
        "    mask = a[\"mask\"].to(device)\n",
        "\n",
        "    output = model(ids,mask)\n",
        "    break"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "papermill": {
          "duration": 2.557418,
          "end_time": "2023-06-28T07:18:50.195121",
          "exception": false,
          "start_time": "2023-06-28T07:18:47.637703",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:23.211096Z",
          "iopub.execute_input": "2024-04-21T15:27:23.211394Z",
          "iopub.status.idle": "2024-04-21T15:27:24.093806Z",
          "shell.execute_reply.started": "2024-04-21T15:27:23.211369Z",
          "shell.execute_reply": "2024-04-21T15:27:24.092767Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4yZHvtHR5FO",
        "outputId": "488e085a-5bf3-4381-b778-61e732cff713"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = output[\"logits\"].squeeze(-1).shape"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.027307,
          "end_time": "2023-06-28T07:18:50.236812",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.209505",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:24.095141Z",
          "iopub.execute_input": "2024-04-21T15:27:24.095438Z",
          "iopub.status.idle": "2024-04-21T15:27:24.102328Z",
          "shell.execute_reply.started": "2024-04-21T15:27:24.095408Z",
          "shell.execute_reply": "2024-04-21T15:27:24.101496Z"
        },
        "trusted": true,
        "id": "vRolgwyAR5FP"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "LR=2e-5\n",
        "optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.033736,
          "end_time": "2023-06-28T07:18:50.284707",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.250971",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:24.103688Z",
          "iopub.execute_input": "2024-04-21T15:27:24.103928Z",
          "iopub.status.idle": "2024-04-21T15:27:24.123001Z",
          "shell.execute_reply.started": "2024-04-21T15:27:24.103907Z",
          "shell.execute_reply": "2024-04-21T15:27:24.122352Z"
        },
        "trusted": true,
        "id": "rVbB_b3YR5FP"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# set epochs"
      ],
      "metadata": {
        "id": "au6LYXwuR5FQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 20\n",
        "if debug:\n",
        "    epochs = 1\n",
        "train_steps = int(len(p_train)/train_batch*epochs)\n",
        "print(train_steps)\n",
        "num_steps = int(train_steps*0.1)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "papermill": {
          "duration": 0.026503,
          "end_time": "2023-06-28T07:18:50.325816",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.299313",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:24.123934Z",
          "iopub.execute_input": "2024-04-21T15:27:24.124184Z",
          "iopub.status.idle": "2024-04-21T15:27:24.130037Z",
          "shell.execute_reply.started": "2024-04-21T15:27:24.124162Z",
          "shell.execute_reply": "2024-04-21T15:27:24.129018Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA_VEqMpR5FR",
        "outputId": "8e6aafd9-1dc8-4dea-b9c1-43400c234ccc"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(output,target):\n",
        "    return torch.sqrt(nn.MSELoss()(output,target))"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.024242,
          "end_time": "2023-06-28T07:18:50.365039",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.340797",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:24.131178Z",
          "iopub.execute_input": "2024-04-21T15:27:24.13148Z",
          "iopub.status.idle": "2024-04-21T15:27:24.138481Z",
          "shell.execute_reply.started": "2024-04-21T15:27:24.131451Z",
          "shell.execute_reply": "2024-04-21T15:27:24.137556Z"
        },
        "trusted": true,
        "id": "FMtCUpBXR5FR"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# def training"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.01495,
          "end_time": "2023-06-28T07:18:50.395109",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.380159",
          "status": "completed"
        },
        "tags": [],
        "id": "tqt2YtNMR5FS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training(\n",
        "    train_dataloader,\n",
        "    model,\n",
        "    optimizer,\n",
        "    scheduler\n",
        "):\n",
        "\n",
        "    model.train()\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    allpreds = []\n",
        "    alltargets = []\n",
        "\n",
        "    for a in train_dataloader:\n",
        "\n",
        "        losses = []\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "\n",
        "            ids = a[\"ids\"].to(device,non_blocking=True)\n",
        "            mask = a[\"mask\"].to(device,non_blocking=True)\n",
        "\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            target = a[\"targets\"].to(device,non_blocking=True)\n",
        "            loss = loss_fn(output,target)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "            allpreds.append(output.detach().cpu().numpy())\n",
        "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        del loss\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    allpreds = np.concatenate(allpreds)\n",
        "    alltargets = np.concatenate(alltargets)\n",
        "    losses = np.mean(losses)\n",
        "    train_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n",
        "\n",
        "    return losses,train_rme_loss"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.029401,
          "end_time": "2023-06-28T07:18:50.439727",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.410326",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:24.139598Z",
          "iopub.execute_input": "2024-04-21T15:27:24.139863Z",
          "iopub.status.idle": "2024-04-21T15:27:24.149616Z",
          "shell.execute_reply.started": "2024-04-21T15:27:24.13984Z",
          "shell.execute_reply": "2024-04-21T15:27:24.148819Z"
        },
        "trusted": true,
        "id": "RYRe6kniR5FT"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# def validating"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.014228,
          "end_time": "2023-06-28T07:18:50.468625",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.454397",
          "status": "completed"
        },
        "tags": [],
        "id": "-HtVAgRbR5FU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validating(valid_dataloader,model):\n",
        "\n",
        "    model.eval()\n",
        "    allpreds = []\n",
        "    alltargets = []\n",
        "\n",
        "    for a in valid_dataloader:\n",
        "        losses = []\n",
        "        with torch.no_grad():\n",
        "\n",
        "            ids = a[\"ids\"].to(device)\n",
        "            mask = a[\"mask\"].to(device)\n",
        "\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            target = a[\"targets\"].to(device)\n",
        "            loss = loss_fn(output,target)\n",
        "            losses.append(loss.item())\n",
        "            allpreds.append(output.detach().cpu().numpy())\n",
        "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
        "\n",
        "            del loss\n",
        "\n",
        "    allpreds = np.concatenate(allpreds)\n",
        "    alltargets = np.concatenate(alltargets)\n",
        "    losses = np.mean(losses)\n",
        "    valid_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n",
        "\n",
        "    return allpreds,losses,valid_rme_loss"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.02798,
          "end_time": "2023-06-28T07:18:50.511175",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.483195",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:24.150802Z",
          "iopub.execute_input": "2024-04-21T15:27:24.151088Z",
          "iopub.status.idle": "2024-04-21T15:27:24.163516Z",
          "shell.execute_reply.started": "2024-04-21T15:27:24.151058Z",
          "shell.execute_reply": "2024-04-21T15:27:24.162696Z"
        },
        "trusted": true,
        "id": "27xMlooVR5FU"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if debug2 == False:\n",
        "    for a in range(epochs):\n",
        "        for b in train_dataloader:\n",
        "            break\n",
        "\n",
        "    losses,train_rme_loss = training(train_dataloader,model,optimizer,scheduler)\n",
        "\n",
        "    for a in valid_dataloader:\n",
        "        break"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "papermill": {
          "duration": 112.111069,
          "end_time": "2023-06-28T07:20:42.637548",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.526479",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:24.164664Z",
          "iopub.execute_input": "2024-04-21T15:27:24.164916Z",
          "iopub.status.idle": "2024-04-21T15:27:29.171863Z",
          "shell.execute_reply.started": "2024-04-21T15:27:24.164891Z",
          "shell.execute_reply": "2024-04-21T15:27:29.170817Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtckeX9AR5FV",
        "outputId": "4c511bd8-8dd9-473f-bb99-a9f2245db24e"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Validate"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.016092,
          "end_time": "2023-06-28T07:20:42.670622",
          "exception": false,
          "start_time": "2023-06-28T07:20:42.65453",
          "status": "completed"
        },
        "tags": [],
        "id": "Va8d84YFR5FW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "trainlosses = []\n",
        "vallosses = []\n",
        "bestscore = None\n",
        "trainscores = []\n",
        "validscores = []\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "\n",
        "    print(\"---------------\" + str(epoch) + \"start-------------\")\n",
        "\n",
        "    trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)\n",
        "    trainlosses.append(trainloss)\n",
        "    trainscores.append(trainscore)\n",
        "\n",
        "    print(\"trainscore is \" + str(trainscore))\n",
        "\n",
        "    preds,validloss,valscore=validating(valid_dataloader,model)\n",
        "    vallosses.append(validloss)\n",
        "    validscores.append(valscore)\n",
        "    print(f\"Validation Loss: {validloss:.4f}, Validation Score (RMSE): {valscore:.4f}\")\n",
        "\n",
        "    # è®¡ç®—é¢å¤–çš„æ€§èƒ½æŒ‡æ ‡\n",
        "    preds_binary = (preds > 0.5).astype(int)  # å°†é¢„æµ‹å€¼è½¬æ¢ä¸ºäºŒè¿›åˆ¶æ ‡ç­¾\n",
        "    true_labels = p_valid['label'].values  # éªŒè¯é›†çœŸå®žæ ‡ç­¾\n",
        "\n",
        "\n",
        "    eval_accuracy = accuracy_score(true_labels, preds_binary)\n",
        "    eval_precision = precision_score(true_labels, preds_binary, zero_division=0)\n",
        "    eval_recall = recall_score(true_labels, preds_binary, zero_division=0)\n",
        "    eval_f1 = f1_score(true_labels, preds_binary, zero_division=0)\n",
        "\n",
        "    print(\"valscore is \" + str(valscore))\n",
        "    print(f\"Validation Accuracy: {eval_accuracy:.4f}\")\n",
        "    print(f\"Validation Precision: {eval_precision:.4f}\")\n",
        "    print(f\"Validation Recall: {eval_recall:.4f}\")\n",
        "    print(f\"Validation F1 Score: {eval_f1:.4f}\")\n",
        "\n",
        "    if bestscore is None:\n",
        "        bestscore = valscore\n",
        "\n",
        "        print(\"Save first model\")\n",
        "\n",
        "        state = {\n",
        "                        'state_dict': model.state_dict(),\n",
        "                        'optimizer_dict': optimizer.state_dict(),\n",
        "                        \"bestscore\":bestscore\n",
        "                    }\n",
        "\n",
        "        torch.save(state, \"model0.pth\")\n",
        "\n",
        "    elif bestscore > valscore:\n",
        "\n",
        "        bestscore = valscore\n",
        "        print(\"found better point\")\n",
        "        state = {\n",
        "                        'state_dict': model.state_dict(),\n",
        "                        'optimizer_dict': optimizer.state_dict(),\n",
        "                        \"bestscore\":bestscore\n",
        "                    }\n",
        "\n",
        "        torch.save(state, \"model0.pth\")\n",
        "\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "        # æ‰“å°æ€§èƒ½æŒ‡æ ‡ä¸º JSON æ ¼å¼\n",
        "    metrics = {\n",
        "        \"eval_loss\": validloss,\n",
        "        \"eval_accuracy\": eval_accuracy,\n",
        "        \"eval_precision\": eval_precision,\n",
        "        \"eval_recall\": eval_recall,\n",
        "        \"eval_f1\": eval_f1,\n",
        "        \"eval_runtime\": None,  # å¯é€‰ï¼šè®°å½•è¿è¡Œæ—¶é—´\n",
        "        \"eval_samples_per_second\": None,  # å¯é€‰ï¼šè®°å½•æ¯ç§’å¤„ç†çš„æ ·æœ¬æ•°\n",
        "        \"eval_steps_per_second\": None,  # å¯é€‰ï¼šè®°å½•æ¯ç§’å¤„ç†çš„æ­¥éª¤æ•°\n",
        "        \"epoch\": epoch + 1\n",
        "    }\n",
        "    print(f\"Metrics for Epoch {epoch + 1}: {metrics}\")\n",
        ""
      ],
      "metadata": {
        "papermill": {
          "duration": 237.459602,
          "end_time": "2023-06-28T07:24:40.146621",
          "exception": false,
          "start_time": "2023-06-28T07:20:42.687019",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:29.173749Z",
          "iopub.execute_input": "2024-04-21T15:27:29.174135Z",
          "iopub.status.idle": "2024-04-21T15:28:03.846473Z",
          "shell.execute_reply.started": "2024-04-21T15:27:29.174095Z",
          "shell.execute_reply": "2024-04-21T15:28:03.845402Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT3QRK-MR5FW",
        "outputId": "e2a30400-b4cc-4fc7-88dc-f1b1ecbb262d"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.5028074245540494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3332, Validation Score (RMSE): 0.3629\n",
            "valscore is 0.36285566196431784\n",
            "Validation Accuracy: 0.9979\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 0.9959\n",
            "Validation F1 Score: 0.9980\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|â–Œ         | 1/20 [00:21<06:39, 21.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for Epoch 1: {'eval_loss': np.float64(0.3332133889198303), 'eval_accuracy': 0.9979166666666667, 'eval_precision': 1.0, 'eval_recall': 0.9959183673469387, 'eval_f1': 0.9979550102249489, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 1}\n",
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.2677514705092211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1325, Validation Score (RMSE): 0.0901\n",
            "valscore is 0.09008966356305842\n",
            "Validation Accuracy: 0.9979\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 0.9959\n",
            "Validation F1 Score: 0.9980\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|â–ˆ         | 2/20 [00:42<06:21, 21.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for Epoch 2: {'eval_loss': np.float64(0.1325242966413498), 'eval_accuracy': 0.9979166666666667, 'eval_precision': 1.0, 'eval_recall': 0.9959183673469387, 'eval_f1': 0.9979550102249489, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 2}\n",
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.19417022464081843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 15%|â–ˆâ–Œ        | 3/20 [01:00<05:40, 20.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1638, Validation Score (RMSE): 0.1213\n",
            "valscore is 0.12132359042416872\n",
            "Validation Accuracy: 0.9979\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 0.9959\n",
            "Validation F1 Score: 0.9980\n",
            "Metrics for Epoch 3: {'eval_loss': np.float64(0.16378329694271088), 'eval_accuracy': 0.9979166666666667, 'eval_precision': 1.0, 'eval_recall': 0.9959183673469387, 'eval_f1': 0.9979550102249489, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 3}\n",
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.163211939442655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 20%|â–ˆâ–ˆ        | 4/20 [01:20<05:17, 19.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1778, Validation Score (RMSE): 0.1257\n",
            "valscore is 0.12568412519815358\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 4: {'eval_loss': np.float64(0.17775848507881165), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 4}\n",
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.14802524765992864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 5/20 [01:39<04:50, 19.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2369, Validation Score (RMSE): 0.1667\n",
            "valscore is 0.16669940937301742\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 5: {'eval_loss': np.float64(0.23691719770431519), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 5}\n",
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.1385762059268855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [01:58<04:31, 19.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2326, Validation Score (RMSE): 0.1665\n",
            "valscore is 0.16646096019697273\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 6: {'eval_loss': np.float64(0.23259595036506653), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 6}\n",
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.13046281424171416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [02:17<04:10, 19.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1717, Validation Score (RMSE): 0.1202\n",
            "valscore is 0.12024211976958608\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 7: {'eval_loss': np.float64(0.17168231308460236), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 7}\n",
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.12048326702941717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [02:37<03:52, 19.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1602, Validation Score (RMSE): 0.1121\n",
            "valscore is 0.11209337007273684\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 8: {'eval_loss': np.float64(0.16023989021778107), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 8}\n",
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.11773746899650862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [02:57<03:35, 19.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1853, Validation Score (RMSE): 0.1321\n",
            "valscore is 0.13210495945360165\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 9: {'eval_loss': np.float64(0.1852950155735016), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 9}\n",
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.11614409696310277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1155, Validation Score (RMSE): 0.0769\n",
            "valscore is 0.0769169479136932\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [03:18<03:21, 20.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for Epoch 10: {'eval_loss': np.float64(0.11545626074075699), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 10}\n",
            "---------------10start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.11500968687578401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [03:36<02:56, 19.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1287, Validation Score (RMSE): 0.0871\n",
            "valscore is 0.08706901164685409\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 11: {'eval_loss': np.float64(0.12872791290283203), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 11}\n",
            "---------------11start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.10935792193596776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [03:57<02:39, 19.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1334, Validation Score (RMSE): 0.0904\n",
            "valscore is 0.09039897500147778\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 12: {'eval_loss': np.float64(0.13341699540615082), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 12}\n",
            "---------------12start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.11083341571468983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [04:16<02:16, 19.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1222, Validation Score (RMSE): 0.0836\n",
            "valscore is 0.08364946378212097\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 13: {'eval_loss': np.float64(0.12220436334609985), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 13}\n",
            "---------------13start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.10723325903015989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [04:35<01:56, 19.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1291, Validation Score (RMSE): 0.0904\n",
            "valscore is 0.0904425022858084\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 14: {'eval_loss': np.float64(0.12914417684078217), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 14}\n",
            "---------------14start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.1049940011817098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [04:54<01:36, 19.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1229, Validation Score (RMSE): 0.0851\n",
            "valscore is 0.08510221322032435\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 15: {'eval_loss': np.float64(0.12286948412656784), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 15}\n",
            "---------------15start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.10259794179635913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [05:14<01:17, 19.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1359, Validation Score (RMSE): 0.0958\n",
            "valscore is 0.09581955328203969\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 16: {'eval_loss': np.float64(0.135904923081398), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 16}\n",
            "---------------16start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.10355324781230806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [05:32<00:57, 19.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1205, Validation Score (RMSE): 0.0835\n",
            "valscore is 0.08350769040515192\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 17: {'eval_loss': np.float64(0.1205160841345787), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 17}\n",
            "---------------17start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.10412315910436204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [05:53<00:39, 19.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1237, Validation Score (RMSE): 0.0862\n",
            "valscore is 0.08624984052719356\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 18: {'eval_loss': np.float64(0.12366215884685516), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 18}\n",
            "---------------18start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.09958904657308552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [06:11<00:19, 19.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1248, Validation Score (RMSE): 0.0871\n",
            "valscore is 0.08714216549564884\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 19: {'eval_loss': np.float64(0.12482305616140366), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 19}\n",
            "---------------19start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.10250776812437097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [06:31<00:00, 19.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1248, Validation Score (RMSE): 0.0871\n",
            "valscore is 0.08714216549564884\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 20: {'eval_loss': np.float64(0.12482305616140366), 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 20}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(p_valid['label'],preds, alpha=0.2)\n",
        "plt.title('Validation Prediction Result')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Prediction')\n",
        "plt.show()\n",
        "\n",
        "x = np.arange(epochs)\n",
        "plt.title('Validation Losses')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(x,trainlosses)\n",
        "plt.plot(x,vallosses)\n",
        "plt.show()\n",
        "\n",
        "x = np.arange(epochs)\n",
        "plt.title('Validation Scores')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Score')\n",
        "plt.plot(x,trainscores)\n",
        "plt.plot(x,validscores)\n",
        "plt.show()"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.775119,
          "end_time": "2023-06-28T07:24:40.942226",
          "exception": false,
          "start_time": "2023-06-28T07:24:40.167107",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:28:03.847986Z",
          "iopub.execute_input": "2024-04-21T15:28:03.848381Z",
          "iopub.status.idle": "2024-04-21T15:28:04.73517Z",
          "shell.execute_reply.started": "2024-04-21T15:28:03.848349Z",
          "shell.execute_reply": "2024-04-21T15:28:04.734256Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KW16uQfKR5FX",
        "outputId": "21b07430-cfda-4d0e-9a9e-e33d0b6d580f"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save model"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.020963,
          "end_time": "2023-06-28T07:24:41.06684",
          "exception": false,
          "start_time": "2023-06-28T07:24:41.045877",
          "status": "completed"
        },
        "tags": [],
        "id": "UjAy8-gPR5Fj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    bestscores = []\n",
        "    bestscores.append(bestscore)\n",
        "\n",
        "    for fold in range(1,5):\n",
        "\n",
        "        # initializing the data\n",
        "        p_train = train[train[\"kfold\"]!=fold].reset_index(drop=True)\n",
        "        p_valid = train[train[\"kfold\"]==fold].reset_index(drop=True)\n",
        "\n",
        "        train_dataset = BERTDataSet(p_train[\"text\"],p_train[\"label\"])\n",
        "        valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid[\"label\"])\n",
        "\n",
        "        train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=4,pin_memory=True)\n",
        "        valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=4,pin_memory=True)\n",
        "\n",
        "        model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\",num_labels=1)\n",
        "\n",
        "        model.to(device)\n",
        "        LR=2e-5\n",
        "        optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) # AdamW optimizer\n",
        "        train_steps = int(len(p_train)/train_batch*epochs)\n",
        "        num_steps = int(train_steps*0.1)\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)\n",
        "\n",
        "        trainlosses = []\n",
        "        vallosses = []\n",
        "        bestscore = None\n",
        "        trainscores = []\n",
        "        validscores = []\n",
        "\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "\n",
        "            print(\"---------------\" + str(epoch) + \"start-------------\")\n",
        "\n",
        "            trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)\n",
        "            trainlosses.append(trainloss)\n",
        "            trainscores.append(trainscore)\n",
        "\n",
        "            print(\"trainscore is \" + str(trainscore))\n",
        "\n",
        "            preds,validloss,valscore=validating(valid_dataloader,model)\n",
        "            vallosses.append(validloss)\n",
        "            validscores.append(valscore)\n",
        "\n",
        "            print(\"valscore is \" + str(valscore))\n",
        "\n",
        "            if bestscore is None:\n",
        "                bestscore = valscore\n",
        "\n",
        "                print(\"Save first model\")\n",
        "\n",
        "                state = {\n",
        "                                'state_dict': model.state_dict(),\n",
        "                                'optimizer_dict': optimizer.state_dict(),\n",
        "                                \"bestscore\":bestscore\n",
        "                            }\n",
        "\n",
        "                torch.save(state, \"model\" + str(fold) + \".pth\")\n",
        "\n",
        "            elif bestscore > valscore:\n",
        "                bestscore = valscore\n",
        "                print(\"found better point\")\n",
        "\n",
        "                state = {\n",
        "                                'state_dict': model.state_dict(),\n",
        "                                'optimizer_dict': optimizer.state_dict(),\n",
        "                                \"bestscore\":bestscore\n",
        "                            }\n",
        "                torch.save(state, \"model\"+ str(fold) + \".pth\")\n",
        "\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "\n",
        "        bestscores.append(bestscore)\n",
        "\n",
        "    bestscores\n",
        "\n",
        "    np.mean(bestscores)\n",
        "    print(\"my cv is \" + str(np.mean(bestscores)))"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "papermill": {
          "duration": 969.305172,
          "end_time": "2023-06-28T07:40:50.393338",
          "exception": false,
          "start_time": "2023-06-28T07:24:41.088166",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:28:04.736646Z",
          "iopub.execute_input": "2024-04-21T15:28:04.737019Z",
          "iopub.status.idle": "2024-04-21T15:29:18.000052Z",
          "shell.execute_reply.started": "2024-04-21T15:28:04.736983Z",
          "shell.execute_reply": "2024-04-21T15:29:17.998771Z"
        },
        "id": "mTIDDZTXR5Fk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# def predicting\n",
        "not use saved models"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.031167,
          "end_time": "2023-06-28T07:40:50.615833",
          "exception": false,
          "start_time": "2023-06-28T07:40:50.584666",
          "status": "completed"
        },
        "tags": [],
        "id": "jI31nTryR5Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predicting(test_dataloader,model):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    allpreds = []\n",
        "    preds = []\n",
        "    allvalloss=0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for a in test_dataloader:\n",
        "\n",
        "            ids = a[\"ids\"].to(device)\n",
        "            mask = a[\"mask\"].to(device)\n",
        "\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            preds.append(output.cpu().numpy())\n",
        "\n",
        "        preds = np.concatenate(preds)\n",
        "        allpreds.append(preds)\n",
        "\n",
        "    return allpreds"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.043725,
          "end_time": "2023-06-28T07:40:50.691507",
          "exception": false,
          "start_time": "2023-06-28T07:40:50.647782",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:29:20.824121Z",
          "iopub.execute_input": "2024-04-21T15:29:20.824508Z",
          "iopub.status.idle": "2024-04-21T15:29:20.833769Z",
          "shell.execute_reply.started": "2024-04-21T15:29:20.824463Z",
          "shell.execute_reply": "2024-04-21T15:29:20.832868Z"
        },
        "trusted": true,
        "id": "8DSj1aSRR5Fl"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# def predicting2\n",
        "use saved models"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.0315,
          "end_time": "2023-06-28T07:40:50.755384",
          "exception": false,
          "start_time": "2023-06-28T07:40:50.723884",
          "status": "completed"
        },
        "tags": [],
        "id": "RI6s5fMsR5Fm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    #model initialized\n",
        "    model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\",num_labels=1)\n",
        "\n",
        "    pthes = [os.path.join(\"./\",s) for s in os.listdir(\"./\") if \".pth\" in s]\n",
        "\n",
        "    def predicting2(\n",
        "        test_dataloader,\n",
        "        model,\n",
        "        pthes\n",
        "    ):\n",
        "\n",
        "        allpreds = []    \n",
        "        for pth in pthes:\n",
        "\n",
        "            state = torch.load(pth)        \n",
        "            model.load_state_dict(state[\"state_dict\"])\n",
        "            model.to(device)\n",
        "            model.eval()      \n",
        "            preds = []\n",
        "            allvalloss=0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for a in test_dataloader:\n",
        "\n",
        "                    ids = a[\"ids\"].to(device)\n",
        "                    mask = a[\"mask\"].to(device)\n",
        "\n",
        "                    output = model(ids,mask)\n",
        "                    output = output[\"logits\"].squeeze(-1)\n",
        "                    preds.append(output.cpu().numpy())\n",
        "\n",
        "                preds = np.concatenate(preds)           \n",
        "                allpreds.append(preds)\n",
        "\n",
        "        return allpreds"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "papermill": {
          "duration": 2.258999,
          "end_time": "2023-06-28T07:40:53.047403",
          "exception": false,
          "start_time": "2023-06-28T07:40:50.788404",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:29:20.83958Z",
          "iopub.execute_input": "2024-04-21T15:29:20.839877Z",
          "iopub.status.idle": "2024-04-21T15:29:22.259102Z",
          "shell.execute_reply.started": "2024-04-21T15:29:20.839853Z",
          "shell.execute_reply": "2024-04-21T15:29:22.258305Z"
        },
        "id": "Q4eB-8koR5Fm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.05125,
          "end_time": "2023-06-28T07:40:53.153975",
          "exception": false,
          "start_time": "2023-06-28T07:40:53.102725",
          "status": "completed"
        },
        "tags": [],
        "id": "0yKITRCGR5Fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tpreds = predicting(test_dataloader,model)\n",
        "#tpreds = predicting2(test_dataloader,model,pthes)"
      ],
      "metadata": {
        "papermill": {
          "duration": 71.891932,
          "end_time": "2023-06-28T07:42:05.088325",
          "exception": false,
          "start_time": "2023-06-28T07:40:53.196393",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:29:22.260177Z",
          "iopub.execute_input": "2024-04-21T15:29:22.260435Z",
          "iopub.status.idle": "2024-04-21T15:29:30.45845Z",
          "shell.execute_reply.started": "2024-04-21T15:29:22.260412Z",
          "shell.execute_reply": "2024-04-21T15:29:30.457356Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gm29Hi_R5Fo",
        "outputId": "c1066110-79be-4337-cc1b-9ed1248e6e65"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction Result"
      ],
      "metadata": {
        "id": "mtS7yXbdR5Fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = []\n",
        "for p in tpreds[0]:\n",
        "    test_pred+=[p]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-21T15:29:30.46046Z",
          "iopub.execute_input": "2024-04-21T15:29:30.460891Z",
          "iopub.status.idle": "2024-04-21T15:29:30.465747Z",
          "shell.execute_reply.started": "2024-04-21T15:29:30.460858Z",
          "shell.execute_reply": "2024-04-21T15:29:30.4647Z"
        },
        "trusted": true,
        "id": "ctj72KmZR5Fp"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(p_test['label'],test_pred, alpha=0.2)\n",
        "plt.title('Test Prediction Result')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Prediction')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-21T15:29:30.46695Z",
          "iopub.execute_input": "2024-04-21T15:29:30.467268Z",
          "iopub.status.idle": "2024-04-21T15:29:30.733329Z",
          "shell.execute_reply.started": "2024-04-21T15:29:30.467237Z",
          "shell.execute_reply": "2024-04-21T15:29:30.732391Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "461T9nkyR5Fq",
        "outputId": "f4a23e87-edb9-434f-e9f1-12b026123d85"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}