{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8165591,
          "sourceType": "datasetVersion",
          "datasetId": 4831777
        }
      ],
      "dockerImageVersionId": 30512,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Fake/Real News torch RoBERTa",
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "33fe2357d8e24e8cb6166b379fd27356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6768c55a9eda4dafb660b32807984f2e",
              "IPY_MODEL_3fd62e24b5c94f7bb49de0c044a1f766",
              "IPY_MODEL_1a0fa47dd17d423895b9bdc746f61651"
            ],
            "layout": "IPY_MODEL_ed419f4820894ad598ec2542606dadf0"
          }
        },
        "6768c55a9eda4dafb660b32807984f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db5ec7889c2c43e3a39ccde149b9a4cd",
            "placeholder": "​",
            "style": "IPY_MODEL_e94d537e4d2b43deb7be9934727907af",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3fd62e24b5c94f7bb49de0c044a1f766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc43ddc7d4e64040a5cbf27a200c5d80",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d4197dc4be24aeb8427004ab6ddcbcb",
            "value": 25
          }
        },
        "1a0fa47dd17d423895b9bdc746f61651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_658aab95dc8c4f489cc372a764b8c370",
            "placeholder": "​",
            "style": "IPY_MODEL_632aa874cc71474ba4a950b74d1f4ff6",
            "value": " 25.0/25.0 [00:00&lt;00:00, 495B/s]"
          }
        },
        "ed419f4820894ad598ec2542606dadf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db5ec7889c2c43e3a39ccde149b9a4cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e94d537e4d2b43deb7be9934727907af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc43ddc7d4e64040a5cbf27a200c5d80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d4197dc4be24aeb8427004ab6ddcbcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "658aab95dc8c4f489cc372a764b8c370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "632aa874cc71474ba4a950b74d1f4ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1ccd9b551c84a298d5481045ea97372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_304559cadbb24270be37e00c039f7498",
              "IPY_MODEL_0ea59b5943bf4130a264497a538c8358",
              "IPY_MODEL_fcd11686ed4d41edb6327cbca8c94af2"
            ],
            "layout": "IPY_MODEL_820120f54643434c89b5df058d425c46"
          }
        },
        "304559cadbb24270be37e00c039f7498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7620a132aee14307a7b23a4d389df6b0",
            "placeholder": "​",
            "style": "IPY_MODEL_03529602f1084d71893e94142b6c149c",
            "value": "vocab.json: 100%"
          }
        },
        "0ea59b5943bf4130a264497a538c8358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47c7e38195c54aa7acb5c7d57143688c",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91af57c86385494fb2275a85bac58674",
            "value": 898823
          }
        },
        "fcd11686ed4d41edb6327cbca8c94af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e32c99bd71a48e491866c0c890bcd61",
            "placeholder": "​",
            "style": "IPY_MODEL_e0dde688971341789da54ac3f112acc8",
            "value": " 899k/899k [00:00&lt;00:00, 1.30MB/s]"
          }
        },
        "820120f54643434c89b5df058d425c46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7620a132aee14307a7b23a4d389df6b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03529602f1084d71893e94142b6c149c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47c7e38195c54aa7acb5c7d57143688c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91af57c86385494fb2275a85bac58674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e32c99bd71a48e491866c0c890bcd61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0dde688971341789da54ac3f112acc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "883cfd0d1dc84113995afd335575931a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b651be74c1e44578b7a9e55c404f603",
              "IPY_MODEL_4e061f22fdc1408fbcb14fed25591fd5",
              "IPY_MODEL_6de467479934422bb12624005a4fc0bd"
            ],
            "layout": "IPY_MODEL_81533745fe3d46c7835647d1dec8dd41"
          }
        },
        "1b651be74c1e44578b7a9e55c404f603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_544c286b253e4e47b3c69570b0c2c749",
            "placeholder": "​",
            "style": "IPY_MODEL_acdd88ed48604574943ebf9b4ce6d75d",
            "value": "merges.txt: 100%"
          }
        },
        "4e061f22fdc1408fbcb14fed25591fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2abd13f30dbe4a68b043a35142dbfc98",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edbb9b379daf47449f6d44220e8ad575",
            "value": 456318
          }
        },
        "6de467479934422bb12624005a4fc0bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84d217153a4545bd90518a9746fd7948",
            "placeholder": "​",
            "style": "IPY_MODEL_236af82fa3474830bb42d83118b766c4",
            "value": " 456k/456k [00:00&lt;00:00, 8.58MB/s]"
          }
        },
        "81533745fe3d46c7835647d1dec8dd41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "544c286b253e4e47b3c69570b0c2c749": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acdd88ed48604574943ebf9b4ce6d75d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2abd13f30dbe4a68b043a35142dbfc98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edbb9b379daf47449f6d44220e8ad575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84d217153a4545bd90518a9746fd7948": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "236af82fa3474830bb42d83118b766c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72ec3a980720436cbad4c6808d47aa76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbd1866c6ca741fd9806016355ce0adc",
              "IPY_MODEL_d27c859c0cb843609d35cb7c8d4a32b4",
              "IPY_MODEL_5399d6a57b1d4e389893a4356c969be4"
            ],
            "layout": "IPY_MODEL_6b4d5668692e49f0a9483ba413271441"
          }
        },
        "dbd1866c6ca741fd9806016355ce0adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1ccc5bba3b7455ab194330b92adbe15",
            "placeholder": "​",
            "style": "IPY_MODEL_308dd6f728a04e00ba0c4682220edbdd",
            "value": "tokenizer.json: 100%"
          }
        },
        "d27c859c0cb843609d35cb7c8d4a32b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f14537b7aee6494c9858a0e41b969b91",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73948ac1f9fc4994a24e3d029edc133f",
            "value": 1355863
          }
        },
        "5399d6a57b1d4e389893a4356c969be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d910df42d97540358d82d501935562be",
            "placeholder": "​",
            "style": "IPY_MODEL_6301fa27239b4c0f8e63a2e288a2006c",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.48MB/s]"
          }
        },
        "6b4d5668692e49f0a9483ba413271441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1ccc5bba3b7455ab194330b92adbe15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "308dd6f728a04e00ba0c4682220edbdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f14537b7aee6494c9858a0e41b969b91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73948ac1f9fc4994a24e3d029edc133f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d910df42d97540358d82d501935562be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6301fa27239b4c0f8e63a2e288a2006c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b06477054fd4d989501a3b985eaf923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41684035fdd34ab6b1a9a139c345e606",
              "IPY_MODEL_7675e1d8174949fdbce88ad4de9bac2a",
              "IPY_MODEL_8777e32183a9431aa473de3e24767e29"
            ],
            "layout": "IPY_MODEL_8d80dcc3d2854a74850c37386e659aa1"
          }
        },
        "41684035fdd34ab6b1a9a139c345e606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c2a229c17ba4698904ef0bfb75a5d81",
            "placeholder": "​",
            "style": "IPY_MODEL_18029c6453cc4589a6fb3f73690ff7a3",
            "value": "config.json: 100%"
          }
        },
        "7675e1d8174949fdbce88ad4de9bac2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19897a668c72428aafe3cd78a8ec9003",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6812e47bb3fd4d71b1aad4ba9ba63ef0",
            "value": 481
          }
        },
        "8777e32183a9431aa473de3e24767e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c126255982734b96a3def4b1732f434d",
            "placeholder": "​",
            "style": "IPY_MODEL_27196f13c9f5426bb7d36b754bafe345",
            "value": " 481/481 [00:00&lt;00:00, 20.0kB/s]"
          }
        },
        "8d80dcc3d2854a74850c37386e659aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c2a229c17ba4698904ef0bfb75a5d81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18029c6453cc4589a6fb3f73690ff7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19897a668c72428aafe3cd78a8ec9003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6812e47bb3fd4d71b1aad4ba9ba63ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c126255982734b96a3def4b1732f434d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27196f13c9f5426bb7d36b754bafe345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0603eb7883804353a31eddd81ead046c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d335444e26ab445481b191e4f0e094ad",
              "IPY_MODEL_36f0991580654f08954ba2b3e897788e",
              "IPY_MODEL_1536de4ce4234f3db37650a7d0e67a0a"
            ],
            "layout": "IPY_MODEL_1bb394e0b673476291386872dc079794"
          }
        },
        "d335444e26ab445481b191e4f0e094ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26ea0972c19c432388b4a75fdd7cbdc2",
            "placeholder": "​",
            "style": "IPY_MODEL_2bebf9a97f6947cd89967a2d79d97d0e",
            "value": "model.safetensors: 100%"
          }
        },
        "36f0991580654f08954ba2b3e897788e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0408295737946a6be2f428d77f6d179",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_602529f520044711b6c8f0eb7bc3d912",
            "value": 498818054
          }
        },
        "1536de4ce4234f3db37650a7d0e67a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6de2db315434d60850a4f0cebd74c07",
            "placeholder": "​",
            "style": "IPY_MODEL_edd5fbf4826f4ec3b29a363649d3110b",
            "value": " 499M/499M [00:01&lt;00:00, 286MB/s]"
          }
        },
        "1bb394e0b673476291386872dc079794": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26ea0972c19c432388b4a75fdd7cbdc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bebf9a97f6947cd89967a2d79d97d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0408295737946a6be2f428d77f6d179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "602529f520044711b6c8f0eb7bc3d912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6de2db315434d60850a4f0cebd74c07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edd5fbf4826f4ec3b29a363649d3110b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "# import kagglehub\n",
        "# clmentbisaillon_fake_and_real_news_dataset_path = kagglehub.dataset_download('clmentbisaillon/fake-and-real-news-dataset')\n",
        "\n",
        "# print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "1eFngj_edxxd"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fake/Real News torch RoBERTa"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.011403,
          "end_time": "2023-06-28T07:17:27.450013",
          "exception": false,
          "start_time": "2023-06-28T07:17:27.43861",
          "status": "completed"
        },
        "tags": [],
        "id": "K2DYK8UCdxxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chardet"
      ],
      "metadata": {
        "papermill": {
          "duration": 13.253789,
          "end_time": "2023-06-28T07:17:40.715086",
          "exception": false,
          "start_time": "2023-06-28T07:17:27.461297",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:26:40.782209Z",
          "iopub.execute_input": "2024-04-21T15:26:40.782679Z",
          "iopub.status.idle": "2024-04-21T15:26:53.337291Z",
          "shell.execute_reply.started": "2024-04-21T15:26:40.782652Z",
          "shell.execute_reply": "2024-04-21T15:26:53.336089Z"
        },
        "trusted": true,
        "id": "HvI7Od1qdxxg",
        "outputId": "6a6f87f3-621c-4af9-832c-548070368599",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (5.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "debug = False\n",
        "debug2 = False"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.020191,
          "end_time": "2023-06-28T07:17:40.747178",
          "exception": false,
          "start_time": "2023-06-28T07:17:40.726987",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:26:53.339567Z",
          "iopub.execute_input": "2024-04-21T15:26:53.339878Z",
          "iopub.status.idle": "2024-04-21T15:26:53.344426Z",
          "shell.execute_reply.started": "2024-04-21T15:26:53.339849Z",
          "shell.execute_reply": "2024-04-21T15:26:53.343502Z"
        },
        "trusted": true,
        "id": "TEaDT-Xcdxxg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import transformers\n",
        "import random\n",
        "import chardet\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "papermill": {
          "duration": 6.118647,
          "end_time": "2023-06-28T07:17:46.877542",
          "exception": false,
          "start_time": "2023-06-28T07:17:40.758895",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:26:53.345765Z",
          "iopub.execute_input": "2024-04-21T15:26:53.346075Z",
          "iopub.status.idle": "2024-04-21T15:26:58.063667Z",
          "shell.execute_reply.started": "2024-04-21T15:26:53.346051Z",
          "shell.execute_reply": "2024-04-21T15:26:58.062696Z"
        },
        "trusted": true,
        "id": "aUM5wuhWdxxh",
        "outputId": "b0a32ac2-b6a4-4333-e3c2-9a9db2e2c177",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_seed(SEED):\n",
        "\n",
        "    random.seed(SEED)\n",
        "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "SEED = 508\n",
        "random_seed(SEED)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.026662,
          "end_time": "2023-06-28T07:17:46.916292",
          "exception": false,
          "start_time": "2023-06-28T07:17:46.88963",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:26:58.065958Z",
          "iopub.execute_input": "2024-04-21T15:26:58.066476Z",
          "iopub.status.idle": "2024-04-21T15:26:58.076321Z",
          "shell.execute_reply.started": "2024-04-21T15:26:58.066449Z",
          "shell.execute_reply": "2024-04-21T15:26:58.075448Z"
        },
        "trusted": true,
        "id": "xWt5dajJdxxh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake=pd.read_csv('sampled_fake.csv')\n",
        "fake['label']='fake'\n",
        "true=pd.read_csv('sampled_true.csv')\n",
        "true['label']='true'\n",
        "data=pd.concat([fake[['label','text']],true[['label','text']]],axis=0).reset_index(drop=True)\n",
        "n=len(data)\n",
        "N=list(range(n))\n",
        "random.shuffle(N)\n",
        "data=data.iloc[N]\n",
        "display(data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-21T15:29:32.550689Z",
          "iopub.execute_input": "2024-04-21T15:29:32.550963Z",
          "iopub.status.idle": "2024-04-21T15:29:34.772934Z",
          "shell.execute_reply.started": "2024-04-21T15:29:32.55094Z",
          "shell.execute_reply": "2024-04-21T15:29:34.771554Z"
        },
        "trusted": true,
        "id": "PGRvMJSydxxi",
        "outputId": "53796d25-59d4-4d97-c0e8-4fe11e028dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     label                                               text\n",
              "6158  true  NEW YORK (Reuters) - The race to succeed Repub...\n",
              "6843  true  SEOUL (Reuters) - North Korea used Chinese-mad...\n",
              "3224  fake  A group of people beat a man in a Brooklyn res...\n",
              "4212  true  ROME (Reuters) - Italy s anti-establishment 5-...\n",
              "390   fake   Communism begins where atheism begins. -Karl ...\n",
              "...    ...                                                ...\n",
              "4053  true  WELLINGTON (Reuters) - A final tally in New Ze...\n",
              "3437  fake  As usual Milwaukee s outspoken Sheriff David C...\n",
              "5436  true  WASHINGTON (Reuters) - When President Donald T...\n",
              "6441  true  JAKARTA (Reuters) - Indonesia s speaker of par...\n",
              "4438  true  HARARE (Reuters) - Zimbabwe s President Emmers...\n",
              "\n",
              "[8000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32f40018-e894-4286-9ed7-6dc703a3d9f7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6158</th>\n",
              "      <td>true</td>\n",
              "      <td>NEW YORK (Reuters) - The race to succeed Repub...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6843</th>\n",
              "      <td>true</td>\n",
              "      <td>SEOUL (Reuters) - North Korea used Chinese-mad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3224</th>\n",
              "      <td>fake</td>\n",
              "      <td>A group of people beat a man in a Brooklyn res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4212</th>\n",
              "      <td>true</td>\n",
              "      <td>ROME (Reuters) - Italy s anti-establishment 5-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>fake</td>\n",
              "      <td>Communism begins where atheism begins. -Karl ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4053</th>\n",
              "      <td>true</td>\n",
              "      <td>WELLINGTON (Reuters) - A final tally in New Ze...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3437</th>\n",
              "      <td>fake</td>\n",
              "      <td>As usual Milwaukee s outspoken Sheriff David C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5436</th>\n",
              "      <td>true</td>\n",
              "      <td>WASHINGTON (Reuters) - When President Donald T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6441</th>\n",
              "      <td>true</td>\n",
              "      <td>JAKARTA (Reuters) - Indonesia s speaker of par...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4438</th>\n",
              "      <td>true</td>\n",
              "      <td>HARARE (Reuters) - Zimbabwe s President Emmers...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32f40018-e894-4286-9ed7-6dc703a3d9f7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32f40018-e894-4286-9ed7-6dc703a3d9f7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32f40018-e894-4286-9ed7-6dc703a3d9f7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9552666-ce70-44bf-9121-eb4833dc5905\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9552666-ce70-44bf-9121-eb4833dc5905')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9552666-ce70-44bf-9121-eb4833dc5905 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d488a7e6-d644-4eb6-87a6-e283f203c110\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d488a7e6-d644-4eb6-87a6-e283f203c110 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8000,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"fake\",\n          \"true\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7717,\n        \"samples\": [\n          \" A Minneapolis man is being charged with criminal sexual conduct after being accused of raping a woman on a bus passing through Crookston Friday, according to the Crookston Times. Mohamed Harir Ayanle, 22, was released from the Northwest Regional Correction Center Monday on a $5,000 bond and on the condition that he does not leave Minnesota,  the Times reported.According to the criminal complaint filed with the Minnesota 9th Judicial District Court in Polk County, the suspect  just moved to Minnesota on September 22, 2016 from Somalia. Breitbart News contacted the Crookston Police Department and asked whether Ayanle spoke English, whether he arrived under the federal refugee resettlement program or a different immigration program, and for details on his current visa status, but did not receive a response.Breitbart News also contacted Catholic Charities of St. Paul and Lutheran Social Services, two of the largest resettlement agencies based in Minnesota, and asked if either had helped to resettle Ayanle, but did not receive a response. A sexual assault evidence kit was collected at RiverView Health and the Polk County Sheriff s Office is assisting in the continued investigation,  the Times added.Crookston, a city of 7,800 with a 15 person police force, is located 25 miles southeast of Grand Forks, North Dakota.  Breitbart News\",\n          \" (This March 22 story was corrected to remove reference to Inhofe being chairman in paragraph four) WASHINGTON (Reuters) - A U.S. Senate committee easily passed a bill on Wednesday to enable the nuclear regulator to license advanced nuclear reactors that backers say are safer than conventional plants and can help deal with a growing waste problem. The Nuclear Energy Innovation and Modernization Act requires the Nuclear Regulatory Commission to develop a regulatory framework to enable the licensing of advanced nuclear reactors that could come into development in 10 or 15 years.   The bill passed 18-3 in the Environment and Public Works Committee.  Republican Senator James Inhofe, said the bill is \\u201ccritical for the revitalization and improvement of our nation\\u2019s nuclear energy industry.\\u201d  The bill has brought together some Republicans eager to prevent the United States from falling behind China and Russia in nuclear innovation and Democrats who want to foster technologies that do not emit gases blamed for climate change. But the legislation faces a cloudy future.  The nuclear industry faces competition from cheap natural gas prices and the growing wind and solar power industries. It was uncertain whether the full Senate would debate the bill or if the measure would be absorbed into broader energy legislation. Democratic Senator Sheldon Whitehouse said the bill would help the United States keep its lead in innovation while finding possible solutions to the waste now kept in pools and in casks at conventional nuclear plant sites.    \\u201cIf we can get there, we will have done this country and the world a vital public service,\\u201d Whitehouse said of the potential for the advanced reactors to reduce the waste problem.  A fellow Democrat, Senator Kamala Harris of California - one of several lawmakers who want to see the country find comprehensive, permanent solutions to existing nuclear waste from conventional nuclear plants before moving ahead with new reactors - voted against the bill.  \\u201cSafely disposing of any radioactive material is a key priority of mine to ensure that we leave our environment pristine and unharmed for future generations,\\u201d Harris said, adding that she is willing to help improve the legislation. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns=['label','text']\n",
        "class_names=sorted(data['label'].unique().tolist())\n",
        "print(class_names)\n",
        "N=list(range(len(class_names)))\n",
        "normal_mapping=dict(zip(class_names,N))\n",
        "reverse_mapping=dict(zip(N,class_names))\n",
        "data['label']=data['label'].map(normal_mapping)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.240253,
          "end_time": "2023-06-28T07:18:29.143156",
          "exception": false,
          "start_time": "2023-06-28T07:18:28.902903",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:00.600551Z",
          "iopub.execute_input": "2024-04-21T15:27:00.600848Z",
          "iopub.status.idle": "2024-04-21T15:27:00.617294Z",
          "shell.execute_reply.started": "2024-04-21T15:27:00.600822Z",
          "shell.execute_reply": "2024-04-21T15:27:00.616443Z"
        },
        "trusted": true,
        "id": "lO7cQ5dsdxxi",
        "outputId": "ac07be51-5330-4c6c-d0b2-9168231e7003",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fake', 'true']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(data[0:3000], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.026581,
          "end_time": "2023-06-28T07:18:29.183917",
          "exception": false,
          "start_time": "2023-06-28T07:18:29.157336",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:00.618357Z",
          "iopub.execute_input": "2024-04-21T15:27:00.618653Z",
          "iopub.status.idle": "2024-04-21T15:27:00.668866Z",
          "shell.execute_reply.started": "2024-04-21T15:27:00.618628Z",
          "shell.execute_reply": "2024-04-21T15:27:00.667944Z"
        },
        "trusted": true,
        "id": "WgqMgziRdxxj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-uncased\")\n",
        "tokenizer = transformers.RobertaTokenizer.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "papermill": {
          "duration": 2.112898,
          "end_time": "2023-06-28T07:18:31.309109",
          "exception": false,
          "start_time": "2023-06-28T07:18:29.196211",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:00.67012Z",
          "iopub.execute_input": "2024-04-21T15:27:00.670721Z",
          "iopub.status.idle": "2024-04-21T15:27:04.921664Z",
          "shell.execute_reply.started": "2024-04-21T15:27:00.670688Z",
          "shell.execute_reply": "2024-04-21T15:27:04.92069Z"
        },
        "trusted": true,
        "id": "pbXSojZhdxxj",
        "outputId": "b9250def-b226-4c43-ba04-1810c0bb29d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "33fe2357d8e24e8cb6166b379fd27356",
            "6768c55a9eda4dafb660b32807984f2e",
            "3fd62e24b5c94f7bb49de0c044a1f766",
            "1a0fa47dd17d423895b9bdc746f61651",
            "ed419f4820894ad598ec2542606dadf0",
            "db5ec7889c2c43e3a39ccde149b9a4cd",
            "e94d537e4d2b43deb7be9934727907af",
            "bc43ddc7d4e64040a5cbf27a200c5d80",
            "9d4197dc4be24aeb8427004ab6ddcbcb",
            "658aab95dc8c4f489cc372a764b8c370",
            "632aa874cc71474ba4a950b74d1f4ff6",
            "a1ccd9b551c84a298d5481045ea97372",
            "304559cadbb24270be37e00c039f7498",
            "0ea59b5943bf4130a264497a538c8358",
            "fcd11686ed4d41edb6327cbca8c94af2",
            "820120f54643434c89b5df058d425c46",
            "7620a132aee14307a7b23a4d389df6b0",
            "03529602f1084d71893e94142b6c149c",
            "47c7e38195c54aa7acb5c7d57143688c",
            "91af57c86385494fb2275a85bac58674",
            "3e32c99bd71a48e491866c0c890bcd61",
            "e0dde688971341789da54ac3f112acc8",
            "883cfd0d1dc84113995afd335575931a",
            "1b651be74c1e44578b7a9e55c404f603",
            "4e061f22fdc1408fbcb14fed25591fd5",
            "6de467479934422bb12624005a4fc0bd",
            "81533745fe3d46c7835647d1dec8dd41",
            "544c286b253e4e47b3c69570b0c2c749",
            "acdd88ed48604574943ebf9b4ce6d75d",
            "2abd13f30dbe4a68b043a35142dbfc98",
            "edbb9b379daf47449f6d44220e8ad575",
            "84d217153a4545bd90518a9746fd7948",
            "236af82fa3474830bb42d83118b766c4",
            "72ec3a980720436cbad4c6808d47aa76",
            "dbd1866c6ca741fd9806016355ce0adc",
            "d27c859c0cb843609d35cb7c8d4a32b4",
            "5399d6a57b1d4e389893a4356c969be4",
            "6b4d5668692e49f0a9483ba413271441",
            "f1ccc5bba3b7455ab194330b92adbe15",
            "308dd6f728a04e00ba0c4682220edbdd",
            "f14537b7aee6494c9858a0e41b969b91",
            "73948ac1f9fc4994a24e3d029edc133f",
            "d910df42d97540358d82d501935562be",
            "6301fa27239b4c0f8e63a2e288a2006c",
            "7b06477054fd4d989501a3b985eaf923",
            "41684035fdd34ab6b1a9a139c345e606",
            "7675e1d8174949fdbce88ad4de9bac2a",
            "8777e32183a9431aa473de3e24767e29",
            "8d80dcc3d2854a74850c37386e659aa1",
            "8c2a229c17ba4698904ef0bfb75a5d81",
            "18029c6453cc4589a6fb3f73690ff7a3",
            "19897a668c72428aafe3cd78a8ec9003",
            "6812e47bb3fd4d71b1aad4ba9ba63ef0",
            "c126255982734b96a3def4b1732f434d",
            "27196f13c9f5426bb7d36b754bafe345"
          ]
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33fe2357d8e24e8cb6166b379fd27356"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1ccd9b551c84a298d5481045ea97372"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "883cfd0d1dc84113995afd335575931a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72ec3a980720436cbad4c6808d47aa76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b06477054fd4d989501a3b985eaf923"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_s = train['text'].iloc[0]\n",
        "\n",
        "result1 = tokenizer.encode_plus(test_s)\n",
        "\n",
        "tokenizer.decode(result1[\"input_ids\"])"
      ],
      "metadata": {
        "papermill": {
          "duration": 5.697647,
          "end_time": "2023-06-28T07:18:37.019837",
          "exception": false,
          "start_time": "2023-06-28T07:18:31.32219",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:04.923052Z",
          "iopub.execute_input": "2024-04-21T15:27:04.923347Z",
          "iopub.status.idle": "2024-04-21T15:27:11.313477Z",
          "shell.execute_reply.started": "2024-04-21T15:27:04.923321Z",
          "shell.execute_reply": "2024-04-21T15:27:11.312494Z"
        },
        "trusted": true,
        "id": "xJJh24w7dxxj",
        "outputId": "1eef13de-7ef0-491d-d422-8f7b5ce02e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>The gay mafia has a new corporate  Don. This is the only article you will need to read about the sheer stupidity of left-wing agitators who are crowing about the new religious freedom law in Indiana.Yesterday, Apple CEO Tim Cook, himself a gay man, published an op-ed in The Washington Post with this ominous title:  Pro-discrimination laws are dangerous.  Cook argues that religious freedom laws, like the one signed by Gov. Mike Pence of Indiana last week are  dangerous  to gay people.A debatable point. However, what is not debatable is this: laws that make homosexuality punishable by death are dangerous to gay people.That s why you might be surprised to learn that Cook s company, Apple, does business in four (4) countries that make homosexuality a capital crime. Those countries are Saudi Arabia, the United Arab Emirates, Nigeria, and Qatar.If you zip on over to this page, you can see the list of all of the countries where Apple does business. Those four countries are on the list.We anxiously await CNN s Andrew Cuomo or ABC s George Stephanopoulos to ask Tim Cook to appear on air and explain this glaring inconsistency, which should be obvious even to the average MSNBC viewer.However, we all know that won t happen.Via: DownTrend</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_s.split(\" \"))"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.022816,
          "end_time": "2023-06-28T07:18:37.055794",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.032978",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:11.314643Z",
          "iopub.execute_input": "2024-04-21T15:27:11.31493Z",
          "iopub.status.idle": "2024-04-21T15:27:11.32222Z",
          "shell.execute_reply.started": "2024-04-21T15:27:11.314899Z",
          "shell.execute_reply": "2024-04-21T15:27:11.321279Z"
        },
        "trusted": true,
        "id": "m5eD_8gvdxxk",
        "outputId": "ca8e3bb0-c5cc-48ae-cda4-b1d28e1d9b24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "215"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result2 = tokenizer.encode_plus(\n",
        "    test_s,\n",
        "    add_special_tokens = True,\n",
        "    max_length = 32,\n",
        "    pad_to_max_length = True,\n",
        "    truncation = True\n",
        ")"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.020965,
          "end_time": "2023-06-28T07:18:37.089429",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.068464",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:11.326177Z",
          "iopub.execute_input": "2024-04-21T15:27:11.326432Z",
          "iopub.status.idle": "2024-04-21T15:27:11.336362Z",
          "shell.execute_reply.started": "2024-04-21T15:27:11.326409Z",
          "shell.execute_reply": "2024-04-21T15:27:11.335725Z"
        },
        "trusted": true,
        "id": "QMpJ3G7Pdxxk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(result2[\"input_ids\"])"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.02102,
          "end_time": "2023-06-28T07:18:37.123143",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.102123",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:11.337843Z",
          "iopub.execute_input": "2024-04-21T15:27:11.338107Z",
          "iopub.status.idle": "2024-04-21T15:27:11.349792Z",
          "shell.execute_reply.started": "2024-04-21T15:27:11.338081Z",
          "shell.execute_reply": "2024-04-21T15:27:11.348942Z"
        },
        "trusted": true,
        "id": "MM7VA2gMdxxk",
        "outputId": "4df20049-f648-400c-f37b-c3782708242f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>The gay mafia has a new corporate  Don. This is the only article you will need to read about the sheer stupidity of left-wing agit</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sens = 32\n",
        "\n",
        "train = train.sort_values(\"label\").reset_index(drop=True)\n",
        "\n",
        "train[\"kfold\"] = train.index % 5\n",
        "\n",
        "p_train = train[train[\"kfold\"]!=0].reset_index(drop=True)\n",
        "p_valid = train[train[\"kfold\"]==0].reset_index(drop=True)\n",
        "\n",
        "p_test=test.reset_index(drop=True)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.030376,
          "end_time": "2023-06-28T07:18:37.166117",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.135741",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:11.350926Z",
          "iopub.execute_input": "2024-04-21T15:27:11.351248Z",
          "iopub.status.idle": "2024-04-21T15:27:11.361283Z",
          "shell.execute_reply.started": "2024-04-21T15:27:11.351214Z",
          "shell.execute_reply": "2024-04-21T15:27:11.360591Z"
        },
        "trusted": true,
        "id": "a6ddnCWVdxxk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'token_type_ids' no need in RoBERTa/DeBERTa"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.01246,
          "end_time": "2023-06-28T07:18:37.191756",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.179296",
          "status": "completed"
        },
        "tags": [],
        "id": "kDkKQbCkdxxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataSet(Dataset):\n",
        "\n",
        "    def __init__(self,sentences,targets):\n",
        "        self.sentences = sentences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        bert_sens = tokenizer.encode_plus(\n",
        "                                sentence,\n",
        "                                add_special_tokens = True,\n",
        "                                max_length = max_sens,\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True)\n",
        "\n",
        "        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n",
        "        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n",
        "\n",
        "        target = torch.tensor(self.targets[idx],dtype=torch.float)\n",
        "\n",
        "        return {\n",
        "                'ids': ids,\n",
        "                'mask': mask,\n",
        "\n",
        "                'targets': target\n",
        "            }"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.023548,
          "end_time": "2023-06-28T07:18:37.228036",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.204488",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:11.362223Z",
          "iopub.execute_input": "2024-04-21T15:27:11.362469Z",
          "iopub.status.idle": "2024-04-21T15:27:11.371986Z",
          "shell.execute_reply.started": "2024-04-21T15:27:11.362448Z",
          "shell.execute_reply": "2024-04-21T15:27:11.37122Z"
        },
        "trusted": true,
        "id": "eL26MRSkdxxk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = BERTDataSet(p_train[\"text\"],p_train[\"label\"])\n",
        "valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid[\"label\"])\n",
        "test_dataset = BERTDataSet(p_test[\"text\"],p_test[\"label\"])\n",
        "\n",
        "train_batch = 16\n",
        "valid_batch = 32\n",
        "test_batch = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=8,pin_memory=True)\n",
        "valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=8,pin_memory=True)\n",
        "test_dataloader = DataLoader(test_dataset,batch_size=test_batch,shuffle = False,num_workers=8,pin_memory=True)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.023996,
          "end_time": "2023-06-28T07:18:37.264616",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.24062",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:11.373088Z",
          "iopub.execute_input": "2024-04-21T15:27:11.373525Z",
          "iopub.status.idle": "2024-04-21T15:27:11.382953Z",
          "shell.execute_reply.started": "2024-04-21T15:27:11.373494Z",
          "shell.execute_reply": "2024-04-21T15:27:11.382072Z"
        },
        "trusted": true,
        "id": "ketCNNzudxxk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\",num_labels=1)\n",
        "#model = transformers.BertForSequenceClassification.from_pretrained(\"../input/bert-base-uncased\",num_labels=1)"
      ],
      "metadata": {
        "papermill": {
          "duration": 5.239221,
          "end_time": "2023-06-28T07:18:42.516586",
          "exception": false,
          "start_time": "2023-06-28T07:18:37.277365",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:11.384056Z",
          "iopub.execute_input": "2024-04-21T15:27:11.384979Z",
          "iopub.status.idle": "2024-04-21T15:27:22.908743Z",
          "shell.execute_reply.started": "2024-04-21T15:27:11.384943Z",
          "shell.execute_reply": "2024-04-21T15:27:22.907975Z"
        },
        "trusted": true,
        "id": "0NA_q3XKdxxl",
        "outputId": "0539d7d8-e169-48fd-d1ae-2c3b2920e607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "0603eb7883804353a31eddd81ead046c",
            "d335444e26ab445481b191e4f0e094ad",
            "36f0991580654f08954ba2b3e897788e",
            "1536de4ce4234f3db37650a7d0e67a0a",
            "1bb394e0b673476291386872dc079794",
            "26ea0972c19c432388b4a75fdd7cbdc2",
            "2bebf9a97f6947cd89967a2d79d97d0e",
            "b0408295737946a6be2f428d77f6d179",
            "602529f520044711b6c8f0eb7bc3d912",
            "f6de2db315434d60850a4f0cebd74c07",
            "edd5fbf4826f4ec3b29a363649d3110b"
          ]
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0603eb7883804353a31eddd81ead046c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "model.train()"
      ],
      "metadata": {
        "papermill": {
          "duration": 5.090094,
          "end_time": "2023-06-28T07:18:47.620511",
          "exception": false,
          "start_time": "2023-06-28T07:18:42.530417",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:22.909926Z",
          "iopub.execute_input": "2024-04-21T15:27:22.910275Z",
          "iopub.status.idle": "2024-04-21T15:27:23.209704Z",
          "shell.execute_reply.started": "2024-04-21T15:27:22.910245Z",
          "shell.execute_reply": "2024-04-21T15:27:23.208753Z"
        },
        "trusted": true,
        "id": "b-qSJ3BNdxxl",
        "outputId": "0dec35ee-1fd8-45b7-b4cd-c0b44ca2432c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a in train_dataloader:\n",
        "    ids = a[\"ids\"].to(device)\n",
        "    mask = a[\"mask\"].to(device)\n",
        "\n",
        "    output = model(ids,mask)\n",
        "    break"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "papermill": {
          "duration": 2.557418,
          "end_time": "2023-06-28T07:18:50.195121",
          "exception": false,
          "start_time": "2023-06-28T07:18:47.637703",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:23.211096Z",
          "iopub.execute_input": "2024-04-21T15:27:23.211394Z",
          "iopub.status.idle": "2024-04-21T15:27:24.093806Z",
          "shell.execute_reply.started": "2024-04-21T15:27:23.211369Z",
          "shell.execute_reply": "2024-04-21T15:27:24.092767Z"
        },
        "trusted": true,
        "id": "AqihqYvBdxxl",
        "outputId": "e633792d-8f15-49d2-b835-55ab2a46c98c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = output[\"logits\"].squeeze(-1).shape"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.027307,
          "end_time": "2023-06-28T07:18:50.236812",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.209505",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:24.095141Z",
          "iopub.execute_input": "2024-04-21T15:27:24.095438Z",
          "iopub.status.idle": "2024-04-21T15:27:24.102328Z",
          "shell.execute_reply.started": "2024-04-21T15:27:24.095408Z",
          "shell.execute_reply": "2024-04-21T15:27:24.101496Z"
        },
        "trusted": true,
        "id": "PlVz0_7Jdxxl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "LR=2e-5\n",
        "optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.033736,
          "end_time": "2023-06-28T07:18:50.284707",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.250971",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:24.103688Z",
          "iopub.execute_input": "2024-04-21T15:27:24.103928Z",
          "iopub.status.idle": "2024-04-21T15:27:24.123001Z",
          "shell.execute_reply.started": "2024-04-21T15:27:24.103907Z",
          "shell.execute_reply": "2024-04-21T15:27:24.122352Z"
        },
        "trusted": true,
        "id": "aHYWVcoedxxl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# set epochs"
      ],
      "metadata": {
        "id": "02owmNd_dxxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 10\n",
        "if debug:\n",
        "    epochs = 1\n",
        "train_steps = int(len(p_train)/train_batch*epochs)\n",
        "print(train_steps)\n",
        "num_steps = int(train_steps*0.1)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "papermill": {
          "duration": 0.026503,
          "end_time": "2023-06-28T07:18:50.325816",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.299313",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:24.123934Z",
          "iopub.execute_input": "2024-04-21T15:27:24.124184Z",
          "iopub.status.idle": "2024-04-21T15:27:24.130037Z",
          "shell.execute_reply.started": "2024-04-21T15:27:24.124162Z",
          "shell.execute_reply": "2024-04-21T15:27:24.129018Z"
        },
        "trusted": true,
        "id": "XJXJ_Juwdxxl",
        "outputId": "a712cc06-d288-48f4-f07e-19bbcc3b41cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(output,target):\n",
        "    return torch.sqrt(nn.MSELoss()(output,target))"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.024242,
          "end_time": "2023-06-28T07:18:50.365039",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.340797",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:24.131178Z",
          "iopub.execute_input": "2024-04-21T15:27:24.13148Z",
          "iopub.status.idle": "2024-04-21T15:27:24.138481Z",
          "shell.execute_reply.started": "2024-04-21T15:27:24.131451Z",
          "shell.execute_reply": "2024-04-21T15:27:24.137556Z"
        },
        "trusted": true,
        "id": "kGo0FScidxxl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# def training"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.01495,
          "end_time": "2023-06-28T07:18:50.395109",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.380159",
          "status": "completed"
        },
        "tags": [],
        "id": "xWxLyFS8dxxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training(\n",
        "    train_dataloader,\n",
        "    model,\n",
        "    optimizer,\n",
        "    scheduler\n",
        "):\n",
        "\n",
        "    model.train()\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    allpreds = []\n",
        "    alltargets = []\n",
        "\n",
        "    for a in train_dataloader:\n",
        "\n",
        "        losses = []\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "\n",
        "            ids = a[\"ids\"].to(device,non_blocking=True)\n",
        "            mask = a[\"mask\"].to(device,non_blocking=True)\n",
        "\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            target = a[\"targets\"].to(device,non_blocking=True)\n",
        "            loss = loss_fn(output,target)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "            allpreds.append(output.detach().cpu().numpy())\n",
        "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        del loss\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    allpreds = np.concatenate(allpreds)\n",
        "    alltargets = np.concatenate(alltargets)\n",
        "    losses = np.mean(losses)\n",
        "    train_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n",
        "\n",
        "    return losses,train_rme_loss"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.029401,
          "end_time": "2023-06-28T07:18:50.439727",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.410326",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:24.139598Z",
          "iopub.execute_input": "2024-04-21T15:27:24.139863Z",
          "iopub.status.idle": "2024-04-21T15:27:24.149616Z",
          "shell.execute_reply.started": "2024-04-21T15:27:24.13984Z",
          "shell.execute_reply": "2024-04-21T15:27:24.148819Z"
        },
        "trusted": true,
        "id": "aKHvoFi2dxxl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# def validating"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.014228,
          "end_time": "2023-06-28T07:18:50.468625",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.454397",
          "status": "completed"
        },
        "tags": [],
        "id": "vBIfcCO0dxxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validating(valid_dataloader,model):\n",
        "\n",
        "    model.eval()\n",
        "    allpreds = []\n",
        "    alltargets = []\n",
        "\n",
        "    for a in valid_dataloader:\n",
        "        losses = []\n",
        "        with torch.no_grad():\n",
        "\n",
        "            ids = a[\"ids\"].to(device)\n",
        "            mask = a[\"mask\"].to(device)\n",
        "\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            target = a[\"targets\"].to(device)\n",
        "            loss = loss_fn(output,target)\n",
        "            losses.append(loss.item())\n",
        "            allpreds.append(output.detach().cpu().numpy())\n",
        "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
        "\n",
        "            del loss\n",
        "\n",
        "    allpreds = np.concatenate(allpreds)\n",
        "    alltargets = np.concatenate(alltargets)\n",
        "    losses = np.mean(losses)\n",
        "    valid_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n",
        "\n",
        "    return allpreds,losses,valid_rme_loss"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.02798,
          "end_time": "2023-06-28T07:18:50.511175",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.483195",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:24.150802Z",
          "iopub.execute_input": "2024-04-21T15:27:24.151088Z",
          "iopub.status.idle": "2024-04-21T15:27:24.163516Z",
          "shell.execute_reply.started": "2024-04-21T15:27:24.151058Z",
          "shell.execute_reply": "2024-04-21T15:27:24.162696Z"
        },
        "trusted": true,
        "id": "UCX9CiuLdxxm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if debug2 == False:\n",
        "    for a in range(epochs):\n",
        "        for b in train_dataloader:\n",
        "            break\n",
        "\n",
        "    losses,train_rme_loss = training(train_dataloader,model,optimizer,scheduler)\n",
        "\n",
        "    for a in valid_dataloader:\n",
        "        break"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "papermill": {
          "duration": 112.111069,
          "end_time": "2023-06-28T07:20:42.637548",
          "exception": false,
          "start_time": "2023-06-28T07:18:50.526479",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:24.164664Z",
          "iopub.execute_input": "2024-04-21T15:27:24.164916Z",
          "iopub.status.idle": "2024-04-21T15:27:29.171863Z",
          "shell.execute_reply.started": "2024-04-21T15:27:24.164891Z",
          "shell.execute_reply": "2024-04-21T15:27:29.170817Z"
        },
        "trusted": true,
        "id": "IGvkIKoDdxxm",
        "outputId": "1818ae4c-e92d-44e7-bceb-8db928007fc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Validate"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.016092,
          "end_time": "2023-06-28T07:20:42.670622",
          "exception": false,
          "start_time": "2023-06-28T07:20:42.65453",
          "status": "completed"
        },
        "tags": [],
        "id": "EurVAskhdxxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "trainlosses = []\n",
        "vallosses = []\n",
        "bestscore = None\n",
        "trainscores = []\n",
        "validscores = []\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "\n",
        "    print(\"---------------\" + str(epoch) + \"start-------------\")\n",
        "\n",
        "    trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)\n",
        "    trainlosses.append(trainloss)\n",
        "    trainscores.append(trainscore)\n",
        "\n",
        "    print(\"trainscore is \" + str(trainscore))\n",
        "\n",
        "    preds,validloss,valscore=validating(valid_dataloader,model)\n",
        "    vallosses.append(validloss)\n",
        "    validscores.append(valscore)\n",
        "\n",
        "    # 计算额外的性能指标\n",
        "    preds_binary = (preds > 0.5).astype(int)  # 将预测值转换为二进制标签\n",
        "    true_labels = p_valid['label'].values  # 验证集真实标签\n",
        "\n",
        "\n",
        "    eval_accuracy = accuracy_score(true_labels, preds_binary)\n",
        "    eval_precision = precision_score(true_labels, preds_binary, zero_division=0)\n",
        "    eval_recall = recall_score(true_labels, preds_binary, zero_division=0)\n",
        "    eval_f1 = f1_score(true_labels, preds_binary, zero_division=0)\n",
        "\n",
        "    print(\"valscore is \" + str(valscore))\n",
        "    print(f\"Validation Accuracy: {eval_accuracy:.4f}\")\n",
        "    print(f\"Validation Precision: {eval_precision:.4f}\")\n",
        "    print(f\"Validation Recall: {eval_recall:.4f}\")\n",
        "    print(f\"Validation F1 Score: {eval_f1:.4f}\")\n",
        "\n",
        "    if bestscore is None:\n",
        "        bestscore = valscore\n",
        "\n",
        "        print(\"Save first model\")\n",
        "\n",
        "        state = {\n",
        "                        'state_dict': model.state_dict(),\n",
        "                        'optimizer_dict': optimizer.state_dict(),\n",
        "                        \"bestscore\":bestscore\n",
        "                    }\n",
        "\n",
        "        torch.save(state, \"model0.pth\")\n",
        "\n",
        "    elif bestscore > valscore:\n",
        "\n",
        "        bestscore = valscore\n",
        "        print(\"found better point\")\n",
        "        state = {\n",
        "                        'state_dict': model.state_dict(),\n",
        "                        'optimizer_dict': optimizer.state_dict(),\n",
        "                        \"bestscore\":bestscore\n",
        "                    }\n",
        "\n",
        "        torch.save(state, \"model0.pth\")\n",
        "\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "            # 打印性能指标为 JSON 格式\n",
        "    metrics = {\n",
        "        \"eval_loss\": validloss,\n",
        "        \"eval_accuracy\": eval_accuracy,\n",
        "        \"eval_precision\": eval_precision,\n",
        "        \"eval_recall\": eval_recall,\n",
        "        \"eval_f1\": eval_f1,\n",
        "        \"eval_runtime\": None,  # 可选：记录运行时间\n",
        "        \"eval_samples_per_second\": None,  # 可选：记录每秒处理的样本数\n",
        "        \"eval_steps_per_second\": None,  # 可选：记录每秒处理的步骤数\n",
        "        \"epoch\": epoch + 1\n",
        "    }\n",
        "    print(f\"Metrics for Epoch {epoch + 1}: {metrics}\")\n",
        ""
      ],
      "metadata": {
        "papermill": {
          "duration": 237.459602,
          "end_time": "2023-06-28T07:24:40.146621",
          "exception": false,
          "start_time": "2023-06-28T07:20:42.687019",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:27:29.173749Z",
          "iopub.execute_input": "2024-04-21T15:27:29.174135Z",
          "iopub.status.idle": "2024-04-21T15:28:03.846473Z",
          "shell.execute_reply.started": "2024-04-21T15:27:29.174095Z",
          "shell.execute_reply": "2024-04-21T15:28:03.845402Z"
        },
        "trusted": true,
        "id": "KWM_w4BKdxxm",
        "outputId": "0f94a6eb-0476-4ae9-f522-e50ca1aa52bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.10661302705469676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.09231645568012145\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:28<04:14, 28.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for Epoch 1: {'eval_loss': 0.12491993606090546, 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 1}\n",
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08580552609681723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.07817242494237571\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:55<03:41, 27.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for Epoch 2: {'eval_loss': 0.10356102138757706, 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 2}\n",
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08149863654112187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 30%|███       | 3/10 [01:19<03:00, 25.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.08820158203606748\n",
            "Validation Accuracy: 0.9979\n",
            "Validation Precision: 0.9959\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 0.9980\n",
            "Metrics for Epoch 3: {'eval_loss': 0.10653207451105118, 'eval_accuracy': 0.9979166666666667, 'eval_precision': 0.9959349593495935, 'eval_recall': 1.0, 'eval_f1': 0.9979633401221996, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 3}\n",
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07002632195970004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.034576522072800264\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [01:46<02:38, 26.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for Epoch 4: {'eval_loss': 0.045073412358760834, 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 4}\n",
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.06447244845787013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.02850382741270524\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [02:15<02:16, 27.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for Epoch 5: {'eval_loss': 0.032675761729478836, 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 5}\n",
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.062025046230527264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 60%|██████    | 6/10 [02:36<01:40, 25.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.03246806965811366\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 6: {'eval_loss': 0.03934241458773613, 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 6}\n",
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.056629237312759054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.01801236388629823\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [03:16<01:30, 30.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for Epoch 7: {'eval_loss': 0.019922714680433273, 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 7}\n",
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.05518434044608267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|████████  | 8/10 [03:36<00:53, 26.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.046834292219850776\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 8: {'eval_loss': 0.06071462482213974, 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 8}\n",
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.05323605631204598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 9/10 [03:57<00:24, 24.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.03333584995908666\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 9: {'eval_loss': 0.04282054305076599, 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 9}\n",
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.052874251575392425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 10/10 [04:18<00:00, 25.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.03333584995908666\n",
            "Validation Accuracy: 1.0000\n",
            "Validation Precision: 1.0000\n",
            "Validation Recall: 1.0000\n",
            "Validation F1 Score: 1.0000\n",
            "Metrics for Epoch 10: {'eval_loss': 0.04282054305076599, 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': None, 'eval_samples_per_second': None, 'eval_steps_per_second': None, 'epoch': 10}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(p_valid['label'],preds, alpha=0.2)\n",
        "plt.title('Validation Prediction Result')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Prediction')\n",
        "plt.show()\n",
        "\n",
        "x = np.arange(epochs)\n",
        "plt.title('Validation Losses')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(x,trainlosses)\n",
        "plt.plot(x,vallosses)\n",
        "plt.show()\n",
        "\n",
        "x = np.arange(epochs)\n",
        "plt.title('Validation Scores')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Score')\n",
        "plt.plot(x,trainscores)\n",
        "plt.plot(x,validscores)\n",
        "plt.show()"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.775119,
          "end_time": "2023-06-28T07:24:40.942226",
          "exception": false,
          "start_time": "2023-06-28T07:24:40.167107",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:28:03.847986Z",
          "iopub.execute_input": "2024-04-21T15:28:03.848381Z",
          "iopub.status.idle": "2024-04-21T15:28:04.73517Z",
          "shell.execute_reply.started": "2024-04-21T15:28:03.848349Z",
          "shell.execute_reply": "2024-04-21T15:28:04.734256Z"
        },
        "trusted": true,
        "id": "JY_307rAdxxm",
        "outputId": "02d796f9-a255-4036-b625-1486ccb16be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save model"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.020963,
          "end_time": "2023-06-28T07:24:41.06684",
          "exception": false,
          "start_time": "2023-06-28T07:24:41.045877",
          "status": "completed"
        },
        "tags": [],
        "id": "Iq71FumMdxxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bestscores = []\n",
        "bestscores.append(bestscore)\n",
        "\n",
        "for fold in range(1,5):\n",
        "\n",
        "    # initializing the data\n",
        "    p_train = train[train[\"kfold\"]!=fold].reset_index(drop=True)\n",
        "    p_valid = train[train[\"kfold\"]==fold].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = BERTDataSet(p_train[\"text\"],p_train[\"label\"])\n",
        "    valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid[\"label\"])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=4,pin_memory=True)\n",
        "    valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=4,pin_memory=True)\n",
        "\n",
        "    model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\",num_labels=1)\n",
        "\n",
        "    model.to(device)\n",
        "    LR=2e-5\n",
        "    optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) # AdamW optimizer\n",
        "    train_steps = int(len(p_train)/train_batch*epochs)\n",
        "    num_steps = int(train_steps*0.1)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)\n",
        "\n",
        "    trainlosses = []\n",
        "    vallosses = []\n",
        "    bestscore = None\n",
        "    trainscores = []\n",
        "    validscores = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        print(\"---------------\" + str(epoch) + \"start-------------\")\n",
        "\n",
        "        trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)\n",
        "        trainlosses.append(trainloss)\n",
        "        trainscores.append(trainscore)\n",
        "\n",
        "        print(\"trainscore is \" + str(trainscore))\n",
        "\n",
        "        preds,validloss,valscore=validating(valid_dataloader,model)\n",
        "        vallosses.append(validloss)\n",
        "        validscores.append(valscore)\n",
        "\n",
        "        print(\"valscore is \" + str(valscore))\n",
        "\n",
        "        if bestscore is None:\n",
        "            bestscore = valscore\n",
        "\n",
        "            print(\"Save first model\")\n",
        "\n",
        "            state = {\n",
        "                            'state_dict': model.state_dict(),\n",
        "                            'optimizer_dict': optimizer.state_dict(),\n",
        "                            \"bestscore\":bestscore\n",
        "                        }\n",
        "\n",
        "            torch.save(state, \"model\" + str(fold) + \".pth\")\n",
        "\n",
        "        elif bestscore > valscore:\n",
        "            bestscore = valscore\n",
        "            print(\"found better point\")\n",
        "\n",
        "            state = {\n",
        "                            'state_dict': model.state_dict(),\n",
        "                            'optimizer_dict': optimizer.state_dict(),\n",
        "                            \"bestscore\":bestscore\n",
        "                        }\n",
        "            torch.save(state, \"model\"+ str(fold) + \".pth\")\n",
        "\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "\n",
        "    bestscores.append(bestscore)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "papermill": {
          "duration": 969.305172,
          "end_time": "2023-06-28T07:40:50.393338",
          "exception": false,
          "start_time": "2023-06-28T07:24:41.088166",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:28:04.736646Z",
          "iopub.execute_input": "2024-04-21T15:28:04.737019Z",
          "iopub.status.idle": "2024-04-21T15:29:18.000052Z",
          "shell.execute_reply.started": "2024-04-21T15:28:04.736983Z",
          "shell.execute_reply": "2024-04-21T15:29:17.998771Z"
        },
        "trusted": true,
        "id": "SJ0dErzIdxxn",
        "outputId": "6e777b5b-f288-4a6f-fedb-096fc20a29e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.3773956468486755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.15404584842049243\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:27<04:11, 27.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.1008663066222514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.08540248682885747\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:55<03:41, 27.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.090731469661457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.07242531787791362\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [01:21<03:09, 27.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07856935553372377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.06520575663710756\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [01:49<02:44, 27.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07234104190561104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 50%|█████     | 5/10 [02:08<02:02, 24.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.07441353334654252\n",
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.06952543957681726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 60%|██████    | 6/10 [02:27<01:29, 22.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.07022596372004719\n",
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.06764391744861321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 70%|███████   | 7/10 [02:46<01:03, 21.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.07568968779117269\n",
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.06673683596981057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|████████  | 8/10 [03:06<00:41, 20.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.07314514088599441\n",
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.06277035562609067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 9/10 [03:25<00:20, 20.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.07820205762536792\n",
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.061783690480831745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 10/10 [03:43<00:00, 22.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.07552316644232628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.3819437484542208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.07604071438804925\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:24<03:41, 24.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.10822326235213342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.06359038784596446\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:48<03:12, 24.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08512321682338783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 30%|███       | 3/10 [01:06<02:29, 21.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.06571361513570348\n",
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07730048925286896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 40%|████      | 4/10 [01:26<02:03, 20.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.06661163502818075\n",
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07354652752539927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.04674856947444789\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:53<01:56, 23.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.06787685328683614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 60%|██████    | 6/10 [02:12<01:25, 21.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.07702855259716555\n",
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.06365425108761387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.045923715590400475\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [02:36<01:07, 22.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.05711631554647757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|████████  | 8/10 [02:56<00:43, 21.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.061479427854782887\n",
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.054511207590470886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 9/10 [03:14<00:20, 20.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.050382846316904296\n",
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.05478524515753347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 10/10 [03:33<00:00, 21.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.0587382045912022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.42226296705455757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.05699049860535047\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:24<03:42, 24.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.10698996760588693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.04589056901243208\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:48<03:15, 24.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08849441503996526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.03969318455719223\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [01:15<02:56, 25.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07687640516908126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 40%|████      | 4/10 [01:34<02:16, 22.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.06072769927527971\n",
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07555128345526725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.02864157930037906\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [02:02<02:03, 24.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07165685258779181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 60%|██████    | 6/10 [02:20<01:30, 22.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.06223392848271986\n",
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.06571411471247915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 70%|███████   | 7/10 [02:39<01:03, 21.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.038063652598084106\n",
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.06453585733518116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.026177701194825834\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [03:05<00:45, 22.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.06132268319618199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 9/10 [03:24<00:21, 21.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.02901017754600735\n",
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.060483651453611335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 10/10 [03:42<00:00, 22.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.03353832546493266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.4576354638169117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.1553425545079533\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:26<03:56, 26.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.09678225423016563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.10697145967369741\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:51<03:25, 25.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08428903975943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.07177699017599824\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [01:19<03:05, 26.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07885180296823899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 40%|████      | 4/10 [01:38<02:22, 23.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.07713799164468851\n",
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.06341850486719086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.0677841404810336\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [02:03<02:01, 24.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.06089058347636494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.06518192495506321\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [02:30<01:39, 24.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.057395052240699816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 70%|███████   | 7/10 [02:48<01:08, 22.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.06596133959917716\n",
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.05810162186911318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|████████  | 8/10 [03:06<00:42, 21.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.07282305318154081\n",
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.05353826379855179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 9/10 [03:25<00:20, 20.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.07641902588591472\n",
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.05302444787311282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 10/10 [03:43<00:00, 22.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.07085738385882238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bestscores"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.04631,
          "end_time": "2023-06-28T07:40:50.474497",
          "exception": false,
          "start_time": "2023-06-28T07:40:50.428187",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:29:18.002063Z",
          "iopub.execute_input": "2024-04-21T15:29:18.002462Z",
          "iopub.status.idle": "2024-04-21T15:29:18.010475Z",
          "shell.execute_reply.started": "2024-04-21T15:29:18.002418Z",
          "shell.execute_reply": "2024-04-21T15:29:18.009599Z"
        },
        "trusted": true,
        "id": "V4vWW-U2dxxn",
        "outputId": "d884b4e9-3a95-4e9b-aeb7-62a849e0a13d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.01801236388629823,\n",
              " 0.06520575663710756,\n",
              " 0.045923715590400475,\n",
              " 0.026177701194825834,\n",
              " 0.06518192495506321]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(bestscores)\n",
        "print(\"my cv is \" + str(np.mean(bestscores)))"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.043282,
          "end_time": "2023-06-28T07:40:50.552707",
          "exception": false,
          "start_time": "2023-06-28T07:40:50.509425",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:29:18.011748Z",
          "iopub.execute_input": "2024-04-21T15:29:18.01202Z",
          "iopub.status.idle": "2024-04-21T15:29:20.822635Z",
          "shell.execute_reply.started": "2024-04-21T15:29:18.011997Z",
          "shell.execute_reply": "2024-04-21T15:29:20.821515Z"
        },
        "trusted": true,
        "id": "GEVzH-vTdxxn",
        "outputId": "2dd41d45-911c-4109-d53b-3ceb03d53d6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my cv is 0.04410029245273907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# def predicting\n",
        "not use saved models"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.031167,
          "end_time": "2023-06-28T07:40:50.615833",
          "exception": false,
          "start_time": "2023-06-28T07:40:50.584666",
          "status": "completed"
        },
        "tags": [],
        "id": "_c0-hAZOdxxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predicting(test_dataloader,model):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    allpreds = []\n",
        "    preds = []\n",
        "    allvalloss=0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for a in test_dataloader:\n",
        "\n",
        "            ids = a[\"ids\"].to(device)\n",
        "            mask = a[\"mask\"].to(device)\n",
        "\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            preds.append(output.cpu().numpy())\n",
        "\n",
        "        preds = np.concatenate(preds)\n",
        "        allpreds.append(preds)\n",
        "\n",
        "    return allpreds"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.043725,
          "end_time": "2023-06-28T07:40:50.691507",
          "exception": false,
          "start_time": "2023-06-28T07:40:50.647782",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:29:20.824121Z",
          "iopub.execute_input": "2024-04-21T15:29:20.824508Z",
          "iopub.status.idle": "2024-04-21T15:29:20.833769Z",
          "shell.execute_reply.started": "2024-04-21T15:29:20.824463Z",
          "shell.execute_reply": "2024-04-21T15:29:20.832868Z"
        },
        "trusted": true,
        "id": "fxbdzsPAdxxo"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# def predicting2\n",
        "use saved models"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.0315,
          "end_time": "2023-06-28T07:40:50.755384",
          "exception": false,
          "start_time": "2023-06-28T07:40:50.723884",
          "status": "completed"
        },
        "tags": [],
        "id": "vlm9RgPxdxxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model initialized\n",
        "model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\",num_labels=1)\n",
        "\n",
        "pthes = [os.path.join(\"./\",s) for s in os.listdir(\"./\") if \".pth\" in s]\n",
        "\n",
        "def predicting2(\n",
        "    test_dataloader,\n",
        "    model,\n",
        "    pthes\n",
        "):\n",
        "\n",
        "    allpreds = []\n",
        "    for pth in pthes:\n",
        "\n",
        "        state = torch.load(pth)\n",
        "        model.load_state_dict(state[\"state_dict\"])\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        preds = []\n",
        "        allvalloss=0\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for a in test_dataloader:\n",
        "\n",
        "                ids = a[\"ids\"].to(device)\n",
        "                mask = a[\"mask\"].to(device)\n",
        "\n",
        "                output = model(ids,mask)\n",
        "                output = output[\"logits\"].squeeze(-1)\n",
        "                preds.append(output.cpu().numpy())\n",
        "\n",
        "            preds = np.concatenate(preds)\n",
        "            allpreds.append(preds)\n",
        "\n",
        "    return allpreds"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "papermill": {
          "duration": 2.258999,
          "end_time": "2023-06-28T07:40:53.047403",
          "exception": false,
          "start_time": "2023-06-28T07:40:50.788404",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:29:20.83958Z",
          "iopub.execute_input": "2024-04-21T15:29:20.839877Z",
          "iopub.status.idle": "2024-04-21T15:29:22.259102Z",
          "shell.execute_reply.started": "2024-04-21T15:29:20.839853Z",
          "shell.execute_reply": "2024-04-21T15:29:22.258305Z"
        },
        "trusted": true,
        "id": "x1dwt_tHdxxo",
        "outputId": "0af5875f-e22f-4f44-fda1-14e6ac924cca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.05125,
          "end_time": "2023-06-28T07:40:53.153975",
          "exception": false,
          "start_time": "2023-06-28T07:40:53.102725",
          "status": "completed"
        },
        "tags": [],
        "id": "Nw2_DboHdxxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tpreds = predicting(test_dataloader,model)\n",
        "tpreds = predicting2(test_dataloader,model,pthes)"
      ],
      "metadata": {
        "papermill": {
          "duration": 71.891932,
          "end_time": "2023-06-28T07:42:05.088325",
          "exception": false,
          "start_time": "2023-06-28T07:40:53.196393",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-21T15:29:22.260177Z",
          "iopub.execute_input": "2024-04-21T15:29:22.260435Z",
          "iopub.status.idle": "2024-04-21T15:29:30.45845Z",
          "shell.execute_reply.started": "2024-04-21T15:29:22.260412Z",
          "shell.execute_reply": "2024-04-21T15:29:30.457356Z"
        },
        "trusted": true,
        "id": "Lbfu0XIVdxxo",
        "outputId": "e09a09be-b6e3-447e-e36c-1d3f2d527262",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction Result"
      ],
      "metadata": {
        "id": "FaeGnHLfdxxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = []\n",
        "for p in tpreds[0]:\n",
        "    test_pred+=[p]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-21T15:29:30.46046Z",
          "iopub.execute_input": "2024-04-21T15:29:30.460891Z",
          "iopub.status.idle": "2024-04-21T15:29:30.465747Z",
          "shell.execute_reply.started": "2024-04-21T15:29:30.460858Z",
          "shell.execute_reply": "2024-04-21T15:29:30.4647Z"
        },
        "trusted": true,
        "id": "2OpgeeZIdxxo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(p_test['label'],test_pred, alpha=0.2)\n",
        "plt.title('Test Prediction Result')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Prediction')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-21T15:29:30.46695Z",
          "iopub.execute_input": "2024-04-21T15:29:30.467268Z",
          "iopub.status.idle": "2024-04-21T15:29:30.733329Z",
          "shell.execute_reply.started": "2024-04-21T15:29:30.467237Z",
          "shell.execute_reply": "2024-04-21T15:29:30.732391Z"
        },
        "trusted": true,
        "id": "SB2V2v8edxxp",
        "outputId": "be0654ba-4b03-4c9e-9872-6ecfe6dfa6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "papermill": {
          "duration": 0.035752,
          "end_time": "2023-06-28T07:42:05.284595",
          "exception": false,
          "start_time": "2023-06-28T07:42:05.248843",
          "status": "completed"
        },
        "tags": [],
        "id": "elUjzolzdxxp"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}